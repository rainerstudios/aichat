Directory structure:
└── bracesproul-langgraphjs-examples/
    ├── README.md
    ├── human_in_the_loop/
    │   ├── README.md
    │   ├── langgraph.json
    │   ├── package.json
    │   ├── tsconfig.json
    │   ├── .env.example
    │   └── src/
    │       ├── dynamic_breakpoints.ts
    │       ├── human_in_the_loop.ts
    │       └── utils.ts
    ├── intro/
    │   ├── README.md
    │   ├── langgraph.json
    │   ├── package.json
    │   ├── tsconfig.json
    │   ├── .env.example
    │   └── src/
    │       └── index.ts
    ├── stockbroker/
    │   ├── README.md
    │   ├── package.json
    │   ├── turbo.json
    │   ├── backend/
    │   │   ├── langgraph.json
    │   │   ├── package.json
    │   │   ├── tsconfig.json
    │   │   ├── .env.example
    │   │   └── src/
    │   │       ├── index.ts
    │   │       ├── tools.ts
    │   │       └── types.ts
    │   └── frontend/
    │       ├── components.json
    │       ├── next.config.mjs
    │       ├── package.json
    │       ├── postcss.config.mjs
    │       ├── tailwind.config.ts
    │       ├── tsconfig.json
    │       ├── vercel.json
    │       ├── .env.example
    │       ├── .eslintrc.json
    │       ├── .prettierrc
    │       └── src/
    │           ├── constants.ts
    │           ├── types.ts
    │           ├── app/
    │           │   ├── globals.css
    │           │   ├── layout.tsx
    │           │   ├── page.tsx
    │           │   └── api/
    │           │       └── [..._path]/
    │           │           └── route.ts
    │           ├── components/
    │           │   ├── Alert.tsx
    │           │   ├── APIDocsAlert.tsx
    │           │   ├── ChatInterface.tsx
    │           │   ├── HomeComponent.tsx
    │           │   ├── InputArea.tsx
    │           │   ├── Interrupted.tsx
    │           │   ├── Message.tsx
    │           │   ├── MessageList.tsx
    │           │   ├── Settings.tsx
    │           │   ├── SkeletonMessage.tsx
    │           │   └── ToolCall.tsx
    │           └── utils/
    │               ├── chatApi.ts
    │               ├── cookies.ts
    │               ├── shadcnUtils.ts
    │               └── streamHandler.ts
    ├── streaming_messages/
    │   ├── README.md
    │   ├── langgraph.json
    │   ├── package.json
    │   ├── tsconfig.json
    │   ├── .env.example
    │   └── src/
    │       ├── utils.ts
    │       ├── langgraph_sdk/
    │       │   ├── stream_events.ts
    │       │   ├── stream_messages.ts
    │       │   ├── stream_updates.ts
    │       │   └── stream_values.ts
    │       └── runnable/
    │           ├── graph.ts
    │           ├── stream_events.ts
    │           ├── stream_messages.ts
    │           ├── stream_updates.ts
    │           └── stream_values.ts
    └── streaming_messages_frontend/
        ├── README.md
        ├── next.config.mjs
        ├── package.json
        ├── postcss.config.mjs
        ├── tailwind.config.ts
        ├── tsconfig.json
        ├── .env.example
        ├── .eslintrc.json
        ├── .prettierrc
        └── src/
            ├── constants.ts
            ├── types.ts
            ├── app/
            │   ├── globals.css
            │   ├── layout.tsx
            │   ├── page.tsx
            │   └── api/
            │       └── [..._path]/
            │           └── route.ts
            ├── components/
            │   ├── ChatInterface.tsx
            │   ├── HomeComponent.tsx
            │   ├── InputArea.tsx
            │   ├── Interrupted.tsx
            │   ├── Message.tsx
            │   ├── MessageList.tsx
            │   ├── Settings.tsx
            │   ├── SkeletonMessage.tsx
            │   └── ToolCall.tsx
            └── utils/
                ├── chatApi.ts
                ├── cookies.ts
                └── streamHandler.ts

================================================
FILE: README.md
================================================
# LangGraph.js Examples

This repository contains a series of example TypeScript projects which implement LangGraph.js agents.
Each directory focuses on a different problem which LangGraph.js aims to solve/enable solutions for.

## Prerequisites

The following projects all use [LangSmith](https://smith.langchain.com/), LangGraph [Studio](https://github.com/langchain-ai/langgraph-studio) and [Cloud](https://langchain-ai.github.io/langgraph/cloud/), as well as the [LangGraph.js](https://langchain-ai.github.io/langgraphjs/) and [LangChain.js](https://js.langchain.com/v0.2/docs/introduction/) libraries.

Before jumping into any of the projects, you should create a LangSmith account [here](https://smith.langchain.com/), and download the latest LangGraph Studio version [here](https://github.com/langchain-ai/langgraph-studio/releases/latest).

Running LangGraph Studio locally requires [Docker](https://www.docker.com/), so ensure you have it installed _and_ running before starting the Studio (I personally use [OrbStack](https://orbstack.dev/) to manage my Docker containers, which is free to use for personal use).

## Projects

- [Intro](./intro/README.md) - Introduction to LangGraph.js, Studio, and Cloud.
- [Human in the Loop](./human_in_the_loop/README.md) - Introduction to Human in the Loop (HITL) concepts.
- [Stockbroker](./stockbroker/README.md) - A full stack stockbroker & financial analyst app, with HITL for purchasing stocks.
- Streaming Messages ([Examples](./streaming_messages/README.md), [Frontend](./streaming_messages_frontend/README.md)) - Next.js web app connected to a LangGraph Cloud deployment to show off different message streaming types.



================================================
FILE: human_in_the_loop/README.md
================================================
# Human in the Loop

The code for the human in the loop (HITL) conceptual video can be found in this directory.
This directory contains two graphs, located inside the [`dynamic_breakpoints.ts`](./src/dynamic_breakpoints.ts) and [`human_in_the_loop.ts`](./src/human_in_the_loop.ts) files.

The dynamic breakpoints graph is not set in the LangGraph config, as it's meant to be a demonstration of how to run it programmatically.
Because of this, there is also a `main` function inside the file which contains the logic necessary to invoke the graph, update the state, and then re-invoke the graph, carrying on where it left off.

## [YouTube Video](https://www.youtube.com/watch?v=gm-WaPTFQqM)

## Setup

To setup the HITL project, install the dependencies:

```bash
yarn install
```

## Environment variables

The HITL project only requires an OpenAI API key to run. Sign up here:

- OpenAI: https://platform.openai.com/signup

Once you have your API keys, create a `.env` file in this directory and add the following:

```bash
OPENAI_API_KEY=YOUR_API_KEY
```

## Running the dynamic breakpoints graph

To run the dynamic breakpoints graph, which is not setup to run via LangGraph Studio or Cloud by default --this can be easily changed by adding a new graph to the `graphs` field of the LangGraph config file, commenting out the `main` function, and the `checkpointer` passed to the graph where `.compile({})` is called-- you only need to run a single script:

```bash
yarn start:dynamic_breakpoints
```

This should output roughly the following to the terminal:

<details>
<summary>Show terminal output</summary>

```txt
Event: agent


---INTERRUPTING GRAPH TO UPDATE STATE---


---refundAuthorized value before state update--- undefined
---refundAuthorized value after state update--- true

---CONTINUING GRAPH AFTER STATE UPDATE---


Event: tools
{ role: 'tool', content: 'Successfully processed refund for 123' }

Event: agent
{
  role: 'ai',
  content: 'Your refund for order no. 123 has been successfully processed. If you have any other questions or need further assistance, feel free to ask!'
}
```

</details>

## LangGraph Config

The LangGraph configuration file for the HITL project is located inside [`langgraph.json`](langgraph.json). This file defines the HITL graph implemented in the project: `human_in_the_loop`.



================================================
FILE: human_in_the_loop/langgraph.json
================================================
{
  "node_version": "20",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "human_in_the_loop": "./src/human_in_the_loop.ts:graph"
  },
  "env": ".env"
}




================================================
FILE: human_in_the_loop/package.json
================================================
{
  "name": "human-in-the-loop",
  "description": "LangGraph.js examples of human in the loop graphs.",
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "build": "yarn tsc --project tsconfig.json --outDir dist",
    "start:hitl": "tsx --experimental-wasm-modules -r dotenv/config src/human_in_the_loop.ts",
    "start:dynamic_breakpoints": "tsx --experimental-wasm-modules -r dotenv/config src/dynamic_breakpoints.ts",
    "lint": "eslint src",
    "lint:fix": "yarn lint --fix",
    "format": "prettier --write \"**/*.ts\"",
    "format:check": "prettier --check \"**/*.ts\""
  },
  "author": "Brace Sproul",
  "license": "MIT",
  "dependencies": {
    "@langchain/community": "^0.3.34",
    "@langchain/core": "^0.3.42",
    "@langchain/langgraph": "^0.2.54",
    "@langchain/openai": "^0.4.4",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@tsconfig/recommended": "^1.0.2",
    "@typescript-eslint/eslint-plugin": "^5.51.0",
    "@typescript-eslint/parser": "^5.51.0",
    "dotenv": "^16.0.3",
    "eslint": "^8.33.0",
    "eslint-config-airbnb-base": "^15.0.0",
    "eslint-config-prettier": "^8.6.0",
    "eslint-plugin-import": "^2.27.5",
    "eslint-plugin-prettier": "^4.2.1",
    "eslint-plugin-unused-imports": "^3.0.0",
    "prettier": "^2.8.3",
    "tsx": "^3.12.3",
    "typescript": "^5.0.0"
  },
  "resolutions": {
    "@langchain/core": "0.2.31"
  }
}



================================================
FILE: human_in_the_loop/tsconfig.json
================================================
{
  "extends": "@tsconfig/recommended",
  "compilerOptions": {
    "outDir": "dist",
    "lib": [
      "ES2021",
      "ES2022.Object",
      "DOM"
    ],
    "target": "ES2021",
    "module": "nodenext",
    "sourceMap": true,
    "allowSyntheticDefaultImports": true,
    "baseUrl": "./src",
    "declaration": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUnusedParameters": true,
    "useDefineForClassFields": true,
    "strictPropertyInitialization": false
  },
  "exclude": [
    "node_modules/",
    "dist/",
    "tests/"
  ],
  "include": [
    "./src"
  ]
}



================================================
FILE: human_in_the_loop/.env.example
================================================
# ------------------LangSmith tracing------------------
LANGCHAIN_API_KEY=
LANGCHAIN_TRACING_V2=true
LANGCHAIN_CALLBACKS_BACKGROUND=true
# -----------------------------------------------------

OPENAI_API_KEY=



================================================
FILE: human_in_the_loop/src/dynamic_breakpoints.ts
================================================
import {
  END,
  START,
  StateGraph,
  MessagesAnnotation,
  MemorySaver,
  Annotation,
  NodeInterrupt,
} from "@langchain/langgraph";
import { type AIMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import { z } from "zod";
import { tool } from "@langchain/core/tools";
import { logEvent } from "utils.js";

const GraphAnnotation = Annotation.Root({
  ...MessagesAnnotation.spec,
  /**
   * Whether or not permission has been granted to refund the user.
   */
  refundAuthorized: Annotation<boolean>(),
});

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

const processRefundTool = tool(
  (input) => {
    return `Successfully processed refund for ${input.productId}`;
  },
  {
    name: "process_refund",
    description: "Process a refund for a given product ID.",
    schema: z.object({
      productId: z.string().describe("The ID of the product to be refunded."),
    }),
  }
);

const tools = [processRefundTool];

const callTool = async (state: typeof GraphAnnotation.State) => {
  const { messages, refundAuthorized } = state;
  if (!refundAuthorized) {
    throw new NodeInterrupt("Permission to refund is required.");
  }

  const lastMessage = messages[messages.length - 1];
  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  if (messageCastAI._getType() !== "ai" || !messageCastAI.tool_calls?.length) {
    throw new Error("No tools were called.");
  }
  const toolCall = messageCastAI.tool_calls[0];

  // Invoke the tool to process the refund
  const refundResult = await processRefundTool.invoke(toolCall);

  return {
    messages: refundResult,
  };
};

const callModel = async (state: typeof GraphAnnotation.State) => {
  const { messages } = state;

  const llmWithTools = llm.bindTools(tools);
  const result = await llmWithTools.invoke(messages);
  return { messages: [result] };
};

const shouldContinue = (state: typeof GraphAnnotation.State) => {
  const { messages } = state;

  const lastMessage = messages[messages.length - 1];
  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  if (messageCastAI._getType() !== "ai" || !messageCastAI.tool_calls?.length) {
    // LLM did not call any tools, or it's not an AI message, so we should end.
    return END;
  }

  // Tools are provided, so we should continue.
  return "tools";
};

const workflow = new StateGraph(GraphAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", callTool)
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END]);

export const graph = workflow.compile({
  checkpointer: new MemorySaver(),
});

async function main() {
  const config = {
    configurable: { thread_id: "refunder_dynamic" },
    streamMode: "updates" as const,
  };
  const input = {
    messages: [
      {
        role: "user",
        content: "Can I have a refund for my purchase? Order no. 123",
      },
    ],
  };

  for await (const event of await graph.stream(input, config)) {
    const key = Object.keys(event)[0];
    if (key) {
      console.log(`Event: ${key}\n`);
    }
  }

  console.log("\n---INTERRUPTING GRAPH TO UPDATE STATE---\n\n");

  console.log(
    "---refundAuthorized value before state update---",
    (await graph.getState(config)).values.refundAuthorized
  );

  await graph.updateState(config, { refundAuthorized: true });

  console.log(
    "---refundAuthorized value after state update---",
    (await graph.getState(config)).values.refundAuthorized
  );

  console.log("\n---CONTINUING GRAPH AFTER STATE UPDATE---\n\n");

  for await (const event of await graph.stream(null, config)) {
    // Log the event to the terminal
    logEvent(event);
  }
}

main();



================================================
FILE: human_in_the_loop/src/human_in_the_loop.ts
================================================
import {
  END,
  START,
  StateGraph,
  MessagesAnnotation,
  MemorySaver,
  Annotation,
} from "@langchain/langgraph";
import { type AIMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import { z } from "zod";
import { tool } from "@langchain/core/tools";
import { logEvent } from "utils.js";

const GraphAnnotation = Annotation.Root({
  ...MessagesAnnotation.spec,
  /**
   * Whether or not permission has been granted to refund the user.
   */
  refundAuthorized: Annotation<boolean>(),
});

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

const processRefundTool = tool(
  (input) => {
    return `Successfully processed refund for ${input.productId}`;
  },
  {
    name: "process_refund",
    description: "Process a refund for a given product ID.",
    schema: z.object({
      productId: z.string().describe("The ID of the product to be refunded."),
    }),
  }
);

const tools = [processRefundTool];

const callTool = async (state: typeof GraphAnnotation.State) => {
  const { messages, refundAuthorized } = state;
  if (!refundAuthorized) {
    throw new Error("Permission to refund is required.");
  }

  const lastMessage = messages[messages.length - 1];
  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  if (messageCastAI._getType() !== "ai" || !messageCastAI.tool_calls?.length) {
    throw new Error("No tools were called.");
  }
  const toolCall = messageCastAI.tool_calls[0];

  // Invoke the tool to process the refund
  const refundResult = await processRefundTool.invoke(toolCall);

  return {
    messages: refundResult,
  };
};

const callModel = async (state: typeof GraphAnnotation.State) => {
  const { messages } = state;

  const llmWithTools = llm.bindTools(tools);
  const result = await llmWithTools.invoke(messages);
  return { messages: [result] };
};

const shouldContinue = (state: typeof GraphAnnotation.State) => {
  const { messages } = state;

  const lastMessage = messages[messages.length - 1];
  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  if (messageCastAI._getType() !== "ai" || !messageCastAI.tool_calls?.length) {
    // LLM did not call any tools, or it's not an AI message, so we should end.
    return END;
  }

  // Tools are provided, so we should continue.
  return "tools";
};

const workflow = new StateGraph(GraphAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", callTool)
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END]);

export const graph = workflow.compile({
  // Uncomment below to run programmatically.
  // checkpointer: new MemorySaver(),
  interruptBefore: ["tools"],
});

// async function main() {
//   const config = {
//     configurable: { thread_id: "refunder" },
//     streamMode: "updates" as const,
//   };
//   const input = {
//     messages: [
//       {
//         role: "user",
//         content: "Can I have a refund for my purchase? Order no. 123",
//       },
//     ],
//   };

//   for await (const event of await graph.stream(input, config)) {
//     const key = Object.keys(event)[0];
//     if (key) {
//       console.log(`Event: ${key}\n`);
//     }
//   }

//   console.log("\n---INTERRUPTING GRAPH TO UPDATE STATE---\n\n");

//   console.log(
//     "---refundAuthorized value before state update---",
//     (await graph.getState(config)).values.refundAuthorized
//   );

//   await graph.updateState(config, { refundAuthorized: true });

//   console.log(
//     "---refundAuthorized value after state update---",
//     (await graph.getState(config)).values.refundAuthorized
//   );

//   console.log("\n---CONTINUING GRAPH AFTER STATE UPDATE---\n\n");

//   for await (const event of await graph.stream(null, config)) {
//     // Log the event to the terminal
//     logEvent(event);
//   }
// }

// main();



================================================
FILE: human_in_the_loop/src/utils.ts
================================================
export const logEvent = (event: Record<string, any>) => {
  const key = Object.keys(event)[0];
  if (key) {
    console.log(`Event: ${key}`);
    if (Array.isArray(event[key].messages)) {
      const lastMsg = event[key].messages[event[key].messages.length - 1];
      console.log(
        {
          role: lastMsg._getType(),
          content: lastMsg.content,
        },
        "\n"
      );
    } else {
      console.log(
        {
          role: event[key].messages._getType(),
          content: event[key].messages.content,
        },
        "\n"
      );
    }
  }
};

export const logStateUpdate = (newBuildup: string, newPunchline: string) => {
  console.log(
    "Updating state to:",
    {
      buildup: newBuildup,
      punchline: newPunchline,
    },
    "\n"
  );
};

export const logLastMessageToolCalls = (lastMessage: Record<string, any>) => {
  console.log("Last message tool calls:", {
    name: lastMessage.tool_calls[0].name,
    args: lastMessage.tool_calls[0].args,
  });
};



================================================
FILE: intro/README.md
================================================
# Intro

This directory contains a simple LangGraph Graph, built for the introduction video in the LangGraph.js video series.
This directory contains a single graph, located inside the `index.ts` file.

## [YouTube Video](https://www.youtube.com/watch?v=Qu8BYTnh3K0)

## Setup

To setup the intro project, install the dependencies:

```bash
yarn install
```

## Environment variables

The intro project requires Tavily and OpenAI API keys to run. Sign up here:

- OpenAI: https://platform.openai.com/signup
- Tavily: https://tavily.com/

Once you have your API keys, create a `.env` file in this directory and add the following:

```bash
TAVILY_API_KEY=YOUR_API_KEY
OPENAI_API_KEY=YOUR_API_KEY
```

## LangGraph Config

The LangGraph configuration file for the intro project is located inside [`langgraph.json`](langgraph.json). This file defines the single graph implemented in the project: `simple_agent`.


================================================
FILE: intro/langgraph.json
================================================
{
  "node_version": "20",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "simple_agent": "./src/index.ts:graph"
  },
  "env": "../.env"
}


================================================
FILE: intro/package.json
================================================
{
  "name": "financial-expert",
  "description": "Financial expert LangGraph.js example",
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "build": "yarn tsc --project tsconfig.json --outDir dist",
    "start": "tsx --experimental-wasm-modules -r dotenv/config src/index.ts",
    "lint": "eslint src",
    "lint:fix": "yarn lint --fix",
    "format": "prettier --write \"**/*.ts\"",
    "format:check": "prettier --check \"**/*.ts\""
  },
  "author": "Brace Sproul",
  "license": "MIT",
  "dependencies": {
    "@langchain/community": "^0.3.34",
    "@langchain/core": "^0.3.42",
    "@langchain/langgraph": "^0.2.54",
    "@langchain/openai": "^0.4.4",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@tsconfig/recommended": "^1.0.2",
    "@typescript-eslint/eslint-plugin": "^5.51.0",
    "@typescript-eslint/parser": "^5.51.0",
    "dotenv": "^16.0.3",
    "eslint": "^8.33.0",
    "eslint-config-airbnb-base": "^15.0.0",
    "eslint-config-prettier": "^8.6.0",
    "eslint-plugin-import": "^2.27.5",
    "eslint-plugin-prettier": "^4.2.1",
    "eslint-plugin-unused-imports": "^3.0.0",
    "prettier": "^2.8.3",
    "tsx": "^3.12.3",
    "typescript": "^5.0.0"
  },
  "resolutions": {
    "@langchain/core": "0.2.31"
  }
}


================================================
FILE: intro/tsconfig.json
================================================
{
  "extends": "@tsconfig/recommended",
  "compilerOptions": {
    "outDir": "dist",
    "lib": [
      "ES2021",
      "ES2022.Object",
      "DOM"
    ],
    "target": "ES2021",
    "module": "nodenext",
    "sourceMap": true,
    "strict": true,
    "allowSyntheticDefaultImports": true,
    "baseUrl": "./src",
    "declaration": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUnusedParameters": true,
    "useDefineForClassFields": true,
    "strictPropertyInitialization": false
  },
  "exclude": [
    "node_modules/",
    "dist/",
    "tests/"
  ],
  "include": [
    "./src"
  ]
}



================================================
FILE: intro/.env.example
================================================
# ------------------LangSmith tracing------------------
LANGCHAIN_API_KEY=
LANGCHAIN_TRACING_V2=true
LANGCHAIN_CALLBACKS_BACKGROUND=true
# -----------------------------------------------------

TAVILY_API_KEY=
OPENAI_API_KEY=



================================================
FILE: intro/src/index.ts
================================================
import { ToolNode } from "@langchain/langgraph/prebuilt";
import {
  END,
  MessagesAnnotation,
  START,
  StateGraph,
} from "@langchain/langgraph";
import { AIMessage, BaseMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

const webSearchTool = new TavilySearchResults({
  maxResults: 4,
});
const tools = [webSearchTool];

const toolNode = new ToolNode(tools);

const callModel = async (state: typeof MessagesAnnotation.State) => {
  const { messages } = state;

  const llmWithTools = llm.bindTools(tools);
  const result = await llmWithTools.invoke(messages);
  return { messages: [result] };
};

const shouldContinue = (state: typeof MessagesAnnotation.State) => {
  const { messages } = state;

  const lastMessage = messages[messages.length - 1];
  if (
    lastMessage._getType() !== "ai" ||
    !(lastMessage as AIMessage).tool_calls?.length
  ) {
    // LLM did not call any tools, or it's not an AI message, so we should end.
    return END;
  }
  return "tools";
};

/**
 * MessagesAnnotation is a pre-built state annotation imported from @langchain/langgraph.
 * It is the same as the following annotation:
 *
 * ```typescript
 * const MessagesAnnotation = Annotation.Root({
 *   messages: Annotation<BaseMessage[]>({
 *     reducer: messagesStateReducer,
 *     default: () => [systemMessage],
 *   }),
 * });
 * ```
 */
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", toolNode)
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END]);

export const graph = workflow.compile({
  // The LangGraph Studio/Cloud API will automatically add a checkpointer
  // only uncomment if running locally
  // checkpointer: new MemorySaver(),
});



================================================
FILE: stockbroker/README.md
================================================
# Stockbroker Human in the Loop

The code for the Stockbroker Human in the Loop video can be found in this directory. It's setup as a monorepo-style project, with `frontend` and `backend` directories.
The `frontend` directory contains a Next.js application which allows you to interact with the Stockbroker agent via a chat interface.
The backend contains a LangGraph agent which powers the core functionality of the stockbroker.

## Deployment

The stockbroker agent is publicly accessible through two interfaces:

1. API:
> The Cloud API for the stockbroker agent is publicly accessible at the following base URL: `https://stockbrokeragent-bracesprouls-projects.vercel.app/api`
> 
> You can find the REST documentation for the stockbroker agent [here](https://stockbrokeragent-bracesprouls-projects.vercel.app/api/docs).
> 
> *Note* The rest documentation displays a "base URL" which is not exactly correct. To hit the API, you'll need to append `/api` to the end of the base URL listed.

2. Web-based Chat Interface:
> To go along with the API, we've also deployed this web-based chat interface for the stockbroker agent.
>
> You can access, and interact with it [here](https://stockbrokeragent-bracesprouls-projects.vercel.app).

## [YouTube Video](https://youtu.be/td7qNK8_H-0)

## Setup

To setup the stockbroker, install dependencies from the root of the monorepo:

```bash
yarn install
```

This will install all dependencies required by both the frontend and backend projects. You can also run shared commands from the root of the project:

```bash
yarn format

yarn build
```

## Environment variables

### Backend

The backend requires Financial Datasets AI, Tavily and OpenAI API keys to run. Sign up here:

- Financial Datasets AI: https://financialdatasets.ai/
- Tavily: https://tavily.com/
- OpenAI: https://platform.openai.com/signup

Once you have your API keys, create a `.env` file in the [`./backend`](`./backend`) directory and add the following:

```bash
FINANCIAL_DATASETS_API_KEY=YOUR_API_KEY
TAVILY_API_KEY=YOUR_API_KEY
OPENAI_API_KEY=YOUR_API_KEY
```

### Frontend

The frontend requires the production, or local deployment of your agent, along with a LangSmith API key (if calling the production endpoint), and finally the name of the agent to interact with (in this case `stockbroker`).

For local development, you can find the API endpoint in the bottom left of LangGraph Studio, which defaults to `http://localhost:51497`. You can find the production URL in the deployment page of your LangGraph cloud deployment.

Then, set the variables in a `.env` file inside [`./frontend`](./frontend):

```bash
# Only required for production deployments
# LANGCHAIN_API_KEY=YOUR_API_KEY
LANGGRAPH_API_URL=http://localhost:51497
NEXT_PUBLIC_API_URL=http://localhost:3000/api # Or your production URL + /api
NEXT_PUBLIC_LANGGRAPH_GRAPH_ID=stockbroker
```

## LangGraph Config

The LangGraph configuration file for the stockbroker project is located inside [`./backend/langgraph.json`](./backend/langgraph.json). This file defines the stockbroker graph implemented in the project: `stockbroker`.



================================================
FILE: stockbroker/package.json
================================================
{
  "name": "stockbroker-monorepo",
  "private": true,
  "version": "0.0.0",
  "author": "Brace Sproul",
  "license": "MIT",
  "workspaces": [
    "frontend",
    "backend"
  ],
  "scripts": {
    "build": "yarn turbo run build",
    "lint": "yarn turbo run lint",
    "format": "yarn turbo run format"
  },
  "devDependencies": {
    "turbo": "latest"
  },
  "packageManager": "yarn@1.22.19"
}


================================================
FILE: stockbroker/turbo.json
================================================
{
  "$schema": "https://turbo.build/schema.json",
  "globalDependencies": ["**/.env"],
  "tasks": {
    "build": {
      "dependsOn": ["^build"],
      "outputs": ["**/dist/**"]
    },
    "lint": {
      "dependsOn": ["^lint"]
    },
    "format": {
      "dependsOn": ["^format"]
    }
  }
}


================================================
FILE: stockbroker/backend/langgraph.json
================================================
{
  "node_version": "20",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "stockbroker": "./src/index.ts:graph"
  },
  "env": ".env"
}


================================================
FILE: stockbroker/backend/package.json
================================================
{
  "name": "financial-expert",
  "description": "Financial expert LangGraph.js example",
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "build": "yarn tsc --project tsconfig.json --outDir dist",
    "start": "tsx --experimental-wasm-modules -r dotenv/config src/index.ts",
    "format": "prettier --write \"**/*.ts\"",
    "format:check": "prettier --check \"**/*.ts\""
  },
  "author": "Brace Sproul",
  "license": "MIT",
  "dependencies": {
    "@langchain/community": "^0.3.34",
    "@langchain/core": "^0.3.42",
    "@langchain/langgraph": "^0.2.54",
    "@langchain/openai": "^0.4.4",
    "zod": "^3.23.8"
  },
  "devDependencies": {
    "@tsconfig/recommended": "^1.0.2",
    "dotenv": "^16.0.3",
    "prettier": "^2.8.3",
    "tsx": "^4.19.0",
    "typescript": "^5.0.0"
  }
}


================================================
FILE: stockbroker/backend/tsconfig.json
================================================
{
  "extends": "@tsconfig/recommended",
  "compilerOptions": {
    "outDir": "dist",
    "lib": [
      "ES2021",
      "ES2022.Object",
      "DOM"
    ],
    "target": "ES2021",
    "module": "nodenext",
    "sourceMap": true,
    "allowSyntheticDefaultImports": true,
    "baseUrl": "./src",
    "declaration": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUnusedParameters": true,
    "useDefineForClassFields": true,
    "strictPropertyInitialization": false
  },
  "exclude": [
    "node_modules/",
    "dist/",
    "tests/"
  ],
  "include": [
    "./src"
  ]
}



================================================
FILE: stockbroker/backend/.env.example
================================================
# ------------------LangSmith tracing------------------
LANGCHAIN_API_KEY=
LANGCHAIN_TRACING_V2=true
LANGCHAIN_CALLBACKS_BACKGROUND=true
# -----------------------------------------------------

FINANCIAL_DATASETS_API_KEY=
TAVILY_API_KEY=
OPENAI_API_KEY=



================================================
FILE: stockbroker/backend/src/index.ts
================================================
import { ToolNode } from "@langchain/langgraph/prebuilt";
import {
  Annotation,
  END,
  START,
  StateGraph,
  NodeInterrupt,
  MessagesAnnotation,
} from "@langchain/langgraph";
import { BaseMessage, type AIMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import {
  priceSnapshotTool,
  StockPurchase,
  ALL_TOOLS_LIST,
  webSearchTool,
} from "tools.js";
import { z } from "zod";

const GraphAnnotation = Annotation.Root({
  ...MessagesAnnotation.spec,
  requestedStockPurchaseDetails: Annotation<StockPurchase>,
  purchaseConfirmed: Annotation<boolean | undefined>,
});

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

const toolNode = new ToolNode(ALL_TOOLS_LIST);

const callModel = async (state: typeof GraphAnnotation.State) => {
  const { messages } = state;

  const systemMessage = {
    role: "system",
    content:
      "You're an expert financial analyst, tasked with answering the users questions " +
      "about a given company or companies. You do not have up to date information on " +
      "the companies, so you much call tools when answering users questions. " +
      "All financial data tools require a company ticker to be passed in as a parameter. If you " +
      "do not know the ticker, you should use the web search tool to find it.",
  };

  const llmWithTools = llm.bindTools(ALL_TOOLS_LIST);
  const result = await llmWithTools.invoke([systemMessage, ...messages]);
  return { messages: result };
};

const shouldContinue = (state: typeof GraphAnnotation.State) => {
  const { messages, requestedStockPurchaseDetails } = state;

  const lastMessage = messages[messages.length - 1];

  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  if (messageCastAI._getType() !== "ai" || !messageCastAI.tool_calls?.length) {
    // LLM did not call any tools, or it's not an AI message, so we should end.
    return END;
  }

  // If `requestedStockPurchaseDetails` is present, we want to execute the purchase
  if (requestedStockPurchaseDetails) {
    return "execute_purchase";
  }

  const { tool_calls } = messageCastAI;
  if (!tool_calls?.length) {
    throw new Error(
      "Expected tool_calls to be an array with at least one element"
    );
  }

  return tool_calls.map((tc) => {
    if (tc.name === "purchase_stock") {
      // The user is trying to purchase a stock, route to the verify purchase node.
      return "prepare_purchase_details";
    } else {
      return "tools";
    }
  });
};

const findCompanyName = async (companyName: string) => {
  // Use the web search tool to find the ticker symbol for the company.
  const searchResults: string = await webSearchTool.invoke(
    `What is the ticker symbol for ${companyName}?`
  );
  const llmWithTickerOutput = llm.withStructuredOutput(
    z
      .object({
        ticker: z.string().describe("The ticker symbol of the company"),
      })
      .describe(
        `Extract the ticker symbol of ${companyName} from the provided context.`
      ),
    { name: "extract_ticker" }
  );
  const extractedTicker = await llmWithTickerOutput.invoke([
    {
      role: "user",
      content: `Given the following search results, extract the ticker symbol for ${companyName}:\n${searchResults}`,
    },
  ]);

  return extractedTicker.ticker;
};

const preparePurchaseDetails = async (state: typeof GraphAnnotation.State) => {
  const { messages } = state;
  const lastMessage = messages[messages.length - 1];
  if (lastMessage._getType() !== "ai") {
    throw new Error("Expected the last message to be an AI message");
  }

  // Cast here since `tool_calls` does not exist on `BaseMessage`
  const messageCastAI = lastMessage as AIMessage;
  const purchaseStockTool = messageCastAI.tool_calls?.find(
    (tc) => tc.name === "purchase_stock"
  );
  if (!purchaseStockTool) {
    throw new Error(
      "Expected the last AI message to have a purchase_stock tool call"
    );
  }
  let { maxPurchasePrice, companyName, ticker } = purchaseStockTool.args;

  if (!ticker) {
    if (!companyName) {
      // The user did not provide the ticker or the company name.
      // Ask the user for the missing information. Also, if the
      // last message had a tool call we need to add a tool message
      // to the messages array.
      const toolMessages = messageCastAI.tool_calls?.map((tc) => {
        return {
          role: "tool",
          content: `Please provide the missing information for the ${tc.name} tool.`,
          id: tc.id,
        };
      });

      return {
        messages: [
          ...(toolMessages ?? []),
          {
            role: "assistant",
            content:
              "Please provide either the company ticker or the company name to purchase stock.",
          },
        ],
      };
    } else {
      // The user did not provide the ticker, but did provide the company name.
      // Call the `findCompanyName` tool to get the ticker.
      ticker = await findCompanyName(purchaseStockTool.args.companyName);
    }
  }

  if (!maxPurchasePrice) {
    // If `maxPurchasePrice` is not defined, default to the current price.
    const priceSnapshot = await priceSnapshotTool.invoke({ ticker });
    maxPurchasePrice = priceSnapshot.snapshot.price;
  }

  // Now we have the final ticker, we can return the purchase information.
  return {
    requestedStockPurchaseDetails: {
      ticker,
      quantity: purchaseStockTool.args.quantity ?? 1, // Default to one if not provided.
      maxPurchasePrice,
    },
  };
};

const executePurchase = async (state: typeof GraphAnnotation.State) => {
  const { purchaseConfirmed, requestedStockPurchaseDetails } = state;
  if (!requestedStockPurchaseDetails) {
    throw new Error("Expected requestedStockPurchaseDetails to be present");
  }
  if (!purchaseConfirmed) {
    // Interrupt the node to request permission to execute the purchase.
    throw new NodeInterrupt("Please confirm the purchase before executing.");
  }

  const { ticker, quantity, maxPurchasePrice } = requestedStockPurchaseDetails;
  // Execute the purchase. In this demo we'll just return a success message.
  return {
    messages: [
      {
        role: "assistant",
        content:
          `Successfully purchased ${quantity} share(s) of ` +
          `${ticker} at $${maxPurchasePrice}/share.`,
      },
    ],
  };
};

const workflow = new StateGraph(GraphAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", toolNode)
  .addNode("prepare_purchase_details", preparePurchaseDetails)
  .addNode("execute_purchase", executePurchase)
  .addEdge("prepare_purchase_details", "execute_purchase")
  .addEdge("execute_purchase", END)
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue, [
    "tools",
    END,
    "prepare_purchase_details",
    "execute_purchase",
  ]);

export const graph = workflow.compile({
  // The LangGraph Studio/Cloud API will automatically add a checkpointer
  // only uncomment if running locally
  // checkpointer: new MemorySaver(),
});



================================================
FILE: stockbroker/backend/src/tools.ts
================================================
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";
import { tool } from "@langchain/core/tools";
import {
  IncomeStatementsResponse,
  BalanceSheetsResponse,
  CashFlowStatementsResponse,
  CompanyFactsResponse,
  SnapshotResponse,
} from "types.js";
import { z } from "zod";

export async function callFinancialDatasetAPI<
  Output extends Record<string, any> = Record<string, any>
>(fields: {
  endpoint: string;
  params: Record<string, string>;
}): Promise<Output> {
  if (!process.env.FINANCIAL_DATASETS_API_KEY) {
    throw new Error("FINANCIAL_DATASETS_API_KEY is not set");
  }

  const baseURL = "https://api.financialdatasets.ai";
  const queryParams = new URLSearchParams(fields.params).toString();
  const url = `${baseURL}${fields.endpoint}?${queryParams}`;
  const response = await fetch(url, {
    method: "GET",
    headers: {
      "X-API-KEY": process.env.FINANCIAL_DATASETS_API_KEY,
    },
  });

  if (!response.ok) {
    let res: string;
    try {
      res = JSON.stringify(await response.json(), null, 2);
    } catch (_) {
      try {
        res = await response.text();
      } catch (_) {
        res = response.statusText;
      }
    }
    throw new Error(
      `Failed to fetch data from ${fields.endpoint}.\nResponse: ${res}`
    );
  }
  const data = await response.json();
  return data;
}

const incomeStatementsTool = tool(
  async (input) => {
    try {
      const data = await callFinancialDatasetAPI<IncomeStatementsResponse>({
        endpoint: "/financials/income-statements",
        params: {
          ticker: input.ticker,
          period: input.period ?? "annual",
          limit: input.limit.toString() ?? "5",
        },
      });
      return JSON.stringify(data, null);
    } catch (e: any) {
      console.warn("Error fetching income statements", e.message);
      return `An error occurred while fetching income statements: ${e.message}`;
    }
  },
  {
    name: "income_statements",
    description:
      "Retrieves income statements for a specified company, showing detailed financial performance over a chosen time period. The output includes key metrics such as revenue, expenses, profits, and per-share data. Specifically, it provides: ticker, date, period type, revenue, cost of revenue, gross profit, operating expenses, income figures (operating, net, EBIT), tax expenses, earnings per share (basic and diluted), dividends per share, and share count information.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the stock. Example: 'AAPL'"),
      period: z
        .enum(["annual", "quarterly", "ttm"])
        .describe("The time period of the income statement. Example: 'annual'")
        .optional()
        .default("annual"),
      limit: z
        .number()
        .int()
        .positive()
        .describe("The number of income statements to return. Example: 5")
        .optional()
        .default(5),
    }),
  }
);

const balanceSheetsTool = tool(
  async (input) => {
    try {
      const data = await callFinancialDatasetAPI<BalanceSheetsResponse>({
        endpoint: "/financials/balance-sheets",
        params: {
          ticker: input.ticker,
          period: input.period ?? "annual",
          limit: input.limit.toString() ?? "5",
        },
      });
      return JSON.stringify(data, null);
    } catch (e: any) {
      console.warn("Error fetching balance sheets", e.message);
      return `An error occurred while fetching balance sheets: ${e.message}`;
    }
  },
  {
    name: "balance_sheets",
    description:
      "Fetches balance sheets for a given company, providing a snapshot of its financial position at specific points in time. The output includes detailed information on assets (total, current, non-current), liabilities (total, current, non-current), and shareholders' equity. Specific data points include cash and equivalents, inventory, investments, property/plant/equipment, goodwill, debt, payables, retained earnings, and more. The result is a JSON stringified object containing an array of balance sheets.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the stock. Example: 'AAPL'"),
      period: z
        .enum(["annual", "quarterly", "ttm"])
        .describe("The time period of the balance sheet. Example: 'annual'")
        .optional()
        .default("annual"),
      limit: z
        .number()
        .int()
        .positive()
        .describe("The number of balance sheets to return. Example: 5")
        .optional()
        .default(5),
    }),
  }
);

const cashFlowStatementsTool = tool(
  async (input) => {
    try {
      const data = await callFinancialDatasetAPI<CashFlowStatementsResponse>({
        endpoint: "/financials/cash-flow-statements",
        params: {
          ticker: input.ticker,
          period: input.period ?? "annual",
          limit: input.limit.toString() ?? "5",
        },
      });
      return JSON.stringify(data, null);
    } catch (e: any) {
      console.warn("Error fetching cash flow statements", e.message);
      return `An error occurred while fetching cash flow statements: ${e.message}`;
    }
  },
  {
    name: "cash_flow_statements",
    description:
      "Obtains cash flow statements for a company, detailing the inflows and outflows of cash from operating, investing, and financing activities. The result is a JSON stringified object containing an array of cash flow statements. Each statement includes: ticker, date, report period, net cash flows from operations/investing/financing, depreciation and amortization, share-based compensation, capital expenditure, business and investment acquisitions/disposals, debt and equity issuances/repayments, dividends, change in cash and equivalents, and effect of exchange rate changes.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the stock. Example: 'AAPL'"),
      period: z
        .enum(["annual", "quarterly", "ttm"])
        .describe("The period of the cash flow statement. Example: 'annual'")
        .optional()
        .default("annual"),
      limit: z
        .number()
        .int()
        .positive()
        .describe("The number of cash flow statements to return. Example: 5")
        .optional()
        .default(5),
    }),
  }
);

const companyFactsTool = tool(
  async (input) => {
    try {
      const data = await callFinancialDatasetAPI<CompanyFactsResponse>({
        endpoint: "/company/facts",
        params: {
          ticker: input.ticker,
        },
      });
      return JSON.stringify(data, null);
    } catch (e: any) {
      console.warn("Error fetching company facts", e.message);
      return `An error occurred while fetching company facts: ${e.message}`;
    }
  },
  {
    name: "company_facts",
    description:
      "Provides key facts and information about a specified company. The result is a JSON stringified object containing details such as: ticker symbol, company name, CIK number, market capitalization, number of employees, SIC code and description, website URL, listing date, and whether the company is currently active.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the company. Example: 'AAPL'"),
    }),
  }
);

export const priceSnapshotTool = tool(
  async (input) => {
    try {
      const data = await callFinancialDatasetAPI<SnapshotResponse>({
        endpoint: "/prices/snapshot",
        params: {
          ticker: input.ticker,
        },
      });
      return JSON.stringify(data, null);
    } catch (e: any) {
      console.warn("Error fetching price snapshots", e.message);
      return `An error occurred while fetching price snapshots: ${e.message}`;
    }
  },
  {
    name: "price_snapshot",
    description:
      "Retrieves the current stock price and related market data for a given company. The snapshot includes the current price, ticker symbol, day's change in price and percentage, timestamp of the data, and a nanosecond-precision timestamp. This tool should ALWAYS be called before purchasing a stock to ensure the most up-to-date price is used.",
    schema: z.object({
      ticker: z.string().describe("The ticker of the company. Example: 'AAPL'"),
    }),
  }
);

const stockPurchaseSchema = z.object({
  ticker: z.string().describe("The ticker of the stock. Example: 'AAPL'"),
  quantity: z
    .number()
    .int()
    .positive()
    .describe("The quantity of stock to purchase."),
  maxPurchasePrice: z
    .number()
    .positive()
    .describe(
      "The max price at which to purchase the stock. Defaults to the current price."
    ),
});

export type StockPurchase = z.infer<typeof stockPurchaseSchema>;

const purchaseStockTool = tool(
  (input) => {
    return (
      `Please confirm that you want to purchase ${input.quantity} shares of ${input.ticker} at ` +
      `${
        input.maxPurchasePrice
          ? `$${input.maxPurchasePrice} per share`
          : "the current price"
      }.`
    );
  },
  {
    name: "purchase_stock",
    description:
      "This tool should be called when a user wants to purchase a stock.",
    schema: z.object({
      ticker: z
        .string()
        .optional()
        .describe("The ticker of the stock. Example: 'AAPL'"),
      companyName: z
        .string()
        .optional()
        .describe(
          "The name of the company. This field should be populated if you do not know the ticker."
        ),
      quantity: z
        .number()
        .int()
        .positive()
        .optional()
        .describe("The quantity of stock to purchase. Defaults to 1."),
      maxPurchasePrice: z
        .number()
        .positive()
        .optional()
        .describe(
          "The max price at which to purchase the stock. Defaults to the current price."
        ),
    }),
  }
);

export const webSearchTool = new TavilySearchResults({
  maxResults: 2,
});

export const ALL_TOOLS_LIST = [
  incomeStatementsTool,
  balanceSheetsTool,
  cashFlowStatementsTool,
  companyFactsTool,
  priceSnapshotTool,
  purchaseStockTool,
  webSearchTool,
];

export const SIMPLE_TOOLS_LIST = [
  incomeStatementsTool,
  balanceSheetsTool,
  cashFlowStatementsTool,
  companyFactsTool,
  priceSnapshotTool,
  webSearchTool,
];



================================================
FILE: stockbroker/backend/src/types.ts
================================================
/**
 * ----------------------------------------------------
 * ------------------ /company/facts ------------------
 * ----------------------------------------------------
 */
export interface CompanyFacts {
  ticker: string;
  name: string;
  cik: string;
  market_cap: number;
  number_of_employees: number;
  sic_code: string;
  sic_description: string;
  website_url: string;
  listing_date: string;
  is_active: boolean;
}

export interface CompanyFactsResponse {
  company_facts: CompanyFacts;
}

/**
 * ----------------------------------------------------
 * ---------- /financials/income-statements -----------
 * ----------------------------------------------------
 */
export interface IncomeStatement {
  ticker: string;
  calendar_date: string;
  report_period: string;
  period: "quarterly" | "ttm" | "annual";
  revenue: number;
  cost_of_revenue: number;
  gross_profit: number;
  operating_expense: number;
  selling_general_and_administrative_expenses: number;
  research_and_development: number;
  operating_income: number;
  interest_expense: number;
  ebit: number;
  income_tax_expense: number;
  net_income_discontinued_operations: number;
  net_income_non_controlling_interests: number;
  net_income: number;
  net_income_common_stock: number;
  preferred_dividends_impact: number;
  consolidated_income: number;
  earnings_per_share: number;
  earnings_per_share_diluted: number;
  dividends_per_common_share: number;
  weighted_average_shares: number;
  weighted_average_shares_diluted: number;
}

export interface IncomeStatementsResponse {
  income_statements: IncomeStatement[];
}

/**
 * ----------------------------------------------------
 * ------------ /financials/balance-sheets ------------
 * ----------------------------------------------------
 */
export interface BalanceSheet {
  ticker: string;
  calendar_date: string;
  report_period: string;
  period: "quarterly" | "ttm" | "annual";
  total_assets: number;
  current_assets: number;
  cash_and_equivalents: number;
  inventory: number;
  current_investments: number;
  trade_and_non_trade_receivables: number;
  non_current_assets: number;
  property_plant_and_equipment: number;
  goodwill_and_intangible_assets: number;
  investments: number;
  non_current_investments: number;
  outstanding_shares: number;
  tax_assets: number;
  total_liabilities: number;
  current_liabilities: number;
  current_debt: number;
  trade_and_non_trade_payables: number;
  deferred_revenue: number;
  deposit_liabilities: number;
  non_current_liabilities: number;
  non_current_debt: number;
  tax_liabilities: number;
  shareholders_equity: number;
  retained_earnings: number;
  accumulated_other_comprehensive_income: number;
  total_debt: number;
}

export interface BalanceSheetsResponse {
  balance_sheets: BalanceSheet[];
}

/**
 * ----------------------------------------------------
 * --------- /financials/cash-flow-statements ---------
 * ----------------------------------------------------
 */
export interface CashFlowStatement {
  ticker: string;
  calendar_date: string;
  report_period: string;
  period: "quarterly" | "ttm" | "annual";
  net_cash_flow_from_operations: number;
  depreciation_and_amortization: number;
  share_based_compensation: number;
  net_cash_flow_from_investing: number;
  capital_expenditure: number;
  business_acquisitions_and_disposals: number;
  investment_acquisitions_and_disposals: number;
  net_cash_flow_from_financing: number;
  issuance_or_repayment_of_debt_securities: number;
  issuance_or_purchase_of_equity_shares: number;
  dividends_and_other_cash_distributions: number;
  change_in_cash_and_equivalents: number;
  effect_of_exchange_rate_changes: number;
}

export interface CashFlowStatementsResponse {
  cash_flow_statements: CashFlowStatement[];
}

/**
 * ----------------------------------------------------
 * --------- /prices/snapshot ---------
 * ----------------------------------------------------
 */
export interface Snapshot {
  price: number;
  ticker: string;
  day_change: number;
  day_change_percent: number;
  time: string;
  time_nanoseconds: number;
}

export interface SnapshotResponse {
  snapshot: Snapshot;
}

/* ---------------------------------------------------- */



================================================
FILE: stockbroker/frontend/components.json
================================================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  }
}


================================================
FILE: stockbroker/frontend/next.config.mjs
================================================
/** @type {import('next').NextConfig} */
const nextConfig = {};

export default nextConfig;



================================================
FILE: stockbroker/frontend/package.json
================================================
{
  "name": "streaming_chat_frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "format": "prettier --config .prettierrc --write \"src\""
  },
  "dependencies": {
    "@langchain/langgraph-sdk": "^0.0.8",
    "@radix-ui/react-icons": "^1.3.0",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.1",
    "js-cookie": "^3.0.5",
    "lucide-react": "^0.438.0",
    "next": "14.2.7",
    "react": "^18",
    "react-dom": "^18",
    "react-json-view": "^1.21.3",
    "react-markdown": "^9.0.1",
    "tailwind-merge": "^2.5.2",
    "tailwind-scrollbar-hide": "^1.1.7",
    "tailwindcss-animate": "^1.0.7",
    "uuid": "^10.0.0"
  },
  "devDependencies": {
    "@types/js-cookie": "^3.0.6",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "@types/uuid": "^10.0.0",
    "eslint": "^8",
    "eslint-config-next": "14.2.7",
    "postcss": "^8",
    "prettier": "^3.3.3",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}



================================================
FILE: stockbroker/frontend/postcss.config.mjs
================================================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;



================================================
FILE: stockbroker/frontend/tailwind.config.ts
================================================
import type { Config } from "tailwindcss";

const config: Config = {
    darkMode: ["class"],
    content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
  	extend: {
  		backgroundImage: {
  			'gradient-radial': 'radial-gradient(var(--tw-gradient-stops))',
  			'gradient-conic': 'conic-gradient(from 180deg at 50% 50%, var(--tw-gradient-stops))'
  		},
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		},
  		colors: {
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			chart: {
  				'1': 'hsl(var(--chart-1))',
  				'2': 'hsl(var(--chart-2))',
  				'3': 'hsl(var(--chart-3))',
  				'4': 'hsl(var(--chart-4))',
  				'5': 'hsl(var(--chart-5))'
  			}
  		}
  	}
  },
  plugins: [require("tailwind-scrollbar-hide"), require("tailwindcss-animate")],
};
export default config;



================================================
FILE: stockbroker/frontend/tsconfig.json
================================================
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: stockbroker/frontend/vercel.json
================================================
{
  "buildCommand": "yarn build",
  "trailingSlash": false,
  "redirects": [
    {
      "source": "/openapi.json",
      "destination": "/api/openapi.json"
    }
  ]
}



================================================
FILE: stockbroker/frontend/.env.example
================================================
LANGGRAPH_API_URL=http://localhost:8123
NEXT_PUBLIC_API_URL=http://localhost:3000/api
LANGCHAIN_API_KEY=YOUR_API_KEY
NEXT_PUBLIC_LANGGRAPH_GRAPH_ID=YOUR_GRAPH_ID


================================================
FILE: stockbroker/frontend/.eslintrc.json
================================================
{
  "extends": "next/core-web-vitals"
}



================================================
FILE: stockbroker/frontend/.prettierrc
================================================
{
  "$schema": "https://json.schemastore.org/prettierrc",
  "printWidth": 80,
  "tabWidth": 2,
  "useTabs": false,
  "semi": true,
  "singleQuote": false,
  "quoteProps": "as-needed",
  "jsxSingleQuote": false,
  "trailingComma": "es5",
  "bracketSpacing": true,
  "arrowParens": "always",
  "requirePragma": false,
  "insertPragma": false,
  "proseWrap": "preserve",
  "htmlWhitespaceSensitivity": "css",
  "vueIndentScriptAndStyle": false,
  "endOfLine": "lf"
}



================================================
FILE: stockbroker/frontend/src/constants.ts
================================================
export const ASSISTANT_ID_COOKIE = "ls_assistant_id";
export const SEEN_API_TOAST_COOKIE = "ls_seen_api_toast";



================================================
FILE: stockbroker/frontend/src/types.ts
================================================
export type Message = {
  id: string;
  text: string;
  sender: string;
  toolCalls?: ToolCall[];
};

export interface ToolCall {
  id: string;
  name: string;
  args: string;
  result?: any;
}

export type Model = "gpt-4o-mini" | string; // Add other model options as needed



================================================
FILE: stockbroker/frontend/src/app/globals.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --foreground-rgb: 0, 0, 0;
  --background-start-rgb: 214, 219, 220;
  --background-end-rgb: 255, 255, 255;
}

@media (prefers-color-scheme: dark) {
  :root {
    --foreground-rgb: 255, 255, 255;
    --background-start-rgb: 0, 0, 0;
    --background-end-rgb: 0, 0, 0;
  }
}
*::-webkit-scrollbar {
  display: none;
}

a {
  color: rgb(33, 118, 246);
}

@layer utilities {
  .text-balance {
    text-wrap: balance;
  }
  .no-scrollbar::-webkit-scrollbar {
    display: none;
  }

  .no-scrollbar {
    -ms-overflow-style: none; /* IE and Edge */
    scrollbar-width: none; /* Firefox */
  }
}

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
  }
  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}



================================================
FILE: stockbroker/frontend/src/app/layout.tsx
================================================
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";

const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
  title: "Streaming UI chat",
  description: "Streaming UI chat",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={inter.className}>{children}</body>
    </html>
  );
}



================================================
FILE: stockbroker/frontend/src/app/page.tsx
================================================
import { APIDocsAlert } from "@/components/APIDocsAlert";
import ChatInterface from "../components/ChatInterface";

export default function Home() {
  return (
    <main className="h-screen bg-[#212121]">
      <APIDocsAlert />
      <ChatInterface />
    </main>
  );
}



================================================
FILE: stockbroker/frontend/src/app/api/[..._path]/route.ts
================================================
import { NextRequest, NextResponse } from "next/server";

export const runtime = "edge";

function getCorsHeaders() {
  return {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "GET, POST, PUT, PATCH, DELETE, OPTIONS",
    "Access-Control-Allow-Headers": "*",
  };
}

async function handleRequest(req: NextRequest, method: string) {
  try {
    const path = req.nextUrl.pathname.replace(/^\/?api\//, "");
    const url = new URL(req.url);
    const searchParams = new URLSearchParams(url.search);
    searchParams.delete("_path");
    searchParams.delete("nxtP_path");
    const queryString = searchParams.toString()
      ? `?${searchParams.toString()}`
      : "";

    const options: RequestInit = {
      method,
      headers: {
        "x-api-key": process.env.LANGCHAIN_API_KEY || "",
      },
    };

    if (["POST", "PUT", "PATCH"].includes(method)) {
      options.body = await req.text();
    }

    const res = await fetch(
      `${process.env.LANGGRAPH_API_URL}/${path}${queryString}`,
      options
    );

    return new NextResponse(res.body, {
      status: res.status,
      statusText: res.statusText,
      headers: {
        ...res.headers,
        ...getCorsHeaders(),
      },
    });
  } catch (e: any) {
    return NextResponse.json({ error: e.message }, { status: e.status ?? 500 });
  }
}

export const GET = (req: NextRequest) => handleRequest(req, "GET");
export const POST = (req: NextRequest) => handleRequest(req, "POST");
export const PUT = (req: NextRequest) => handleRequest(req, "PUT");
export const PATCH = (req: NextRequest) => handleRequest(req, "PATCH");
export const DELETE = (req: NextRequest) => handleRequest(req, "DELETE");

// Add a new OPTIONS handler
export const OPTIONS = () => {
  return new NextResponse(null, {
    status: 204,
    headers: {
      ...getCorsHeaders(),
    },
  });
};



================================================
FILE: stockbroker/frontend/src/components/Alert.tsx
================================================
import * as React from "react";
import { cva, type VariantProps } from "class-variance-authority";

import { cn } from "@/utils/shadcnUtils";

const alertVariants = cva(
  "relative w-full rounded-lg border px-4 py-3 text-sm [&>svg+div]:translate-y-[-3px] [&>svg]:absolute [&>svg]:left-4 [&>svg]:top-4 [&>svg]:text-foreground [&>svg~*]:pl-7",
  {
    variants: {
      variant: {
        default: "bg-background text-foreground",
        destructive:
          "border-destructive/50 text-destructive dark:border-destructive [&>svg]:text-destructive",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
);

const Alert = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement> & VariantProps<typeof alertVariants>
>(({ className, variant, ...props }, ref) => (
  <div
    ref={ref}
    role="alert"
    className={cn(alertVariants({ variant }), className)}
    {...props}
  />
));
Alert.displayName = "Alert";

const AlertTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h5
    ref={ref}
    className={cn("mb-1 font-medium leading-none tracking-tight", className)}
    {...props}
  />
));
AlertTitle.displayName = "AlertTitle";

const AlertDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm [&_p]:leading-relaxed", className)}
    {...props}
  />
));
AlertDescription.displayName = "AlertDescription";

export { Alert, AlertTitle, AlertDescription };



================================================
FILE: stockbroker/frontend/src/components/APIDocsAlert.tsx
================================================
"use client";

import { useEffect, useState } from "react";
import { getCookie, setCookie } from "@/utils/cookies";
import { SEEN_API_TOAST_COOKIE } from "@/constants";
import { Alert, AlertDescription, AlertTitle } from "@/components/Alert";
import { Terminal, X, Wifi, Book } from "lucide-react";

export function APIDocsAlert() {
  const [showAlert, setShowAlert] = useState(false);
  const [isClosing, setIsClosing] = useState(false);

  useEffect(() => {
    if (showAlert) return;
    if (typeof window === "undefined") return;

    const hasClosesApiToast = getCookie(SEEN_API_TOAST_COOKIE);
    if (hasClosesApiToast) return;

    setShowAlert(true);
  }, []);

  const handleClose = () => {
    setIsClosing(true);
    setTimeout(() => {
      setShowAlert(false);
      if (process.env.NODE_ENV === "development") {
        console.info(
          "API alert closed. Not setting cookie due to development environment."
        );
        return;
      }
      setCookie(SEEN_API_TOAST_COOKIE, "true");
    }, 300); // Match this with the transition duration
  };

  if (!showAlert) {
    return null;
  }

  return (
    <Alert
      className={`max-w-[400px] absolute top-4 left-4 z-50 shadow-lg bg-gray-200 transition-opacity duration-300 ease-in-out ${
        isClosing ? "opacity-0" : "opacity-100"
      }`}
    >
      <div className="flex flex-row w-full justify-between">
        <span className="flex flex-row gap-2 items-center">
          <Terminal className="h-4 w-4" />
          <AlertTitle className="pt-1">
            Want to use the Stockbroker API?
          </AlertTitle>
        </span>
        <span>
          <button
            onClick={handleClose}
            className="text-gray-500 hover:text-gray-700 focus:outline-none focus:ring-2 focus:ring-gray-300 rounded-full p-1 transition-colors duration-200 ease-in-out"
            aria-label="Close alert"
          >
            <X />
          </button>
        </span>
      </div>
      <AlertDescription className="flex flex-col gap-1 py-2">
        <span className="flex flex-row gap-1 items-center justify-normal">
          <Book className="h-4 w-4" />
          <p className="text-black text-sm font-light">
            Click{" "}
            <a
              className="text-blue-600 underline underline-offset-1 font-normal"
              href="https://github.com/bracesproul/langgraphjs-examples/blob/main/stockbroker/README.md"
              target="_blank"
            >
              here
            </a>{" "}
            to read the Stockbroker docs.
          </p>
        </span>
        <span className="flex flex-row gap-1 items-center justify-normal">
          <Wifi className="h-4 w-4" />
          <p className="text-black text-sm font-light">
            {" "}
            Or, click{" "}
            <a
              className="text-blue-600 underline underline-offset-1 font-normal"
              href="/api/docs"
              target="_blank"
            >
              here
            </a>{" "}
            to read the REST API docs.
          </p>
        </span>
      </AlertDescription>
    </Alert>
  );
}



================================================
FILE: stockbroker/frontend/src/components/ChatInterface.tsx
================================================
"use client";

import { useState, useEffect, useRef } from "react";
import { v4 as uuidv4 } from "uuid";
import MessageList from "./MessageList";
import InputArea from "./InputArea";
import HomeComponent from "./HomeComponent";
import Settings from "./Settings";
import { Message, Model } from "../types";
import { handleStreamEvent } from "../utils/streamHandler";
import {
  createAssistant,
  createThread,
  getThreadState,
  sendMessage,
} from "../utils/chatApi";
import { ASSISTANT_ID_COOKIE } from "@/constants";
import { getCookie, setCookie } from "@/utils/cookies";
import { ThreadState } from "@langchain/langgraph-sdk";
import { GraphInterrupt } from "./Interrupted";

export default function ChatInterface() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [threadId, setThreadId] = useState<string | null>(null);
  const [assistantId, setAssistantId] = useState<string | null>(null);
  const [model, setModel] = useState<Model>("gpt-4o-mini" as Model);
  const [userId, setUserId] = useState<string>("");
  const [systemInstructions, setSystemInstructions] = useState<string>("");
  const [isLoading, setIsLoading] = useState(false);
  const [threadState, setThreadState] =
    useState<ThreadState<Record<string, any>>>();
  const [graphInterrupted, setGraphInterrupted] = useState(false);
  const [allowNullMessage, setAllowNullMessage] = useState(false);

  const messageListRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    if (typeof window === "undefined") return;

    const initializeChat = async () => {
      let assistantId = getCookie(ASSISTANT_ID_COOKIE);

      if (!assistantId) {
        const assistant = await createAssistant(
          process.env.NEXT_PUBLIC_LANGGRAPH_GRAPH_ID as string
        );
        assistantId = assistant.assistant_id as string;
        setCookie(ASSISTANT_ID_COOKIE, assistantId);
        setAssistantId(assistantId);
        // Use the assistant ID as the user ID.
        setUserId(assistantId);
      } else {
        setUserId(assistantId);
      }

      const { thread_id } = await createThread();
      setThreadId(thread_id);
      setAssistantId(assistantId);
    };

    initializeChat();
  }, []);

  useEffect(() => {
    if (messageListRef.current) {
      messageListRef.current.scrollTop = messageListRef.current.scrollHeight;
    }
  }, [messages]);

  const handleSendMessage = async (message: string | null) => {
    if (message !== null) {
      setMessages([
        ...messages,
        { text: message, sender: "user", id: uuidv4() },
      ]);
    }

    if (!threadId) {
      console.error("Thread ID is not available");
      return;
    }
    if (!assistantId) {
      console.error("Assistant ID is not available");
      return;
    }

    try {
      setIsLoading(true);
      setThreadState(undefined);
      setGraphInterrupted(false);
      setAllowNullMessage(false);
      const response = await sendMessage({
        threadId,
        assistantId,
        message,
        model,
        userId,
        systemInstructions,
      });

      for await (const chunk of response) {
        handleStreamEvent(chunk, setMessages);
      }

      // Fetch the current state of the thread
      const currentState = await getThreadState(threadId);
      setThreadState(currentState);
      if (currentState.next.length) {
        setGraphInterrupted(true);
      }
      setIsLoading(false);
    } catch (error) {
      console.error("Error streaming messages:", error);
      setIsLoading(false);
    }
  };

  return (
    <div className="w-full h-screen bg-[#212121] overflow-hidden rounded-lg shadow-md">
      <Settings
        onModelChange={setModel}
        onSystemInstructionsChange={setSystemInstructions}
        currentModel={model as any}
        currentSystemInstructions={systemInstructions}
      />
      {messages.length === 0 ? (
        <HomeComponent onMessageSelect={handleSendMessage} />
      ) : (
        <div ref={messageListRef} className="overflow-y-auto h-screen">
          <MessageList messages={messages} isLoading={false} />
          {!!graphInterrupted && !!threadState && !!threadId ? (
            <div className="flex items-center justify-start w-2/3 mx-auto">
              <GraphInterrupt
                setAllowNullMessage={setAllowNullMessage}
                threadId={threadId}
                state={threadState}
              />
            </div>
          ) : null}
          {allowNullMessage && (
            <div className="flex flex-col w-2/3 mx-auto overflow-y-scroll pb-[100px]">
              <button
                onClick={async () => handleSendMessage(null)}
                disabled={isLoading}
                className="bg-blue-500 text-white px-4 py-2 rounded-lg mt-2 max-w-[400px] mx-auto"
              >
                Continue
              </button>
            </div>
          )}
        </div>
      )}
      <InputArea
        disabled={!!graphInterrupted && !!threadState && !!threadId}
        onSendMessage={handleSendMessage}
      />
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/HomeComponent.tsx
================================================
import React from "react";
import Image from "next/image";

const exampleMessages = [
  "What're some facts about Google?",
  "How much revenue did Apple make last year?",
  "Is McDonald's profitable?",
  "What's the current stock price of Tesla?",
];

const HomeComponent: React.FC<{
  onMessageSelect: (message: string) => void;
}> = ({ onMessageSelect }) => {
  return (
    <div className="flex flex-col items-center  justify-center h-full">
      <Image
        src="/logo.jpeg"
        alt="StreamChat"
        width={80}
        height={80}
        className="mb-8 rounded-full"
      />
      <div className="grid grid-cols-2 gap-4">
        {exampleMessages.map((message, index) => (
          <div
            key={index}
            className="bg-transparent border-[1px] border-[#ffffff1a] p-4 rounded-lg text-gray-400 cursor-pointer transition-all duration-500 ease-in-out hover:bg-[#2f2f2f] hover:scale-105"
            onClick={() => onMessageSelect(message)}
          >
            {message}
          </div>
        ))}
      </div>
    </div>
  );
};

export default HomeComponent;



================================================
FILE: stockbroker/frontend/src/components/InputArea.tsx
================================================
import { useState } from "react";

export default function InputArea({
  onSendMessage,
  disabled,
}: {
  onSendMessage: (message: string) => void;
  disabled: boolean;
}) {
  const [input, setInput] = useState("");

  const handleSubmit = (e: React.FormEvent<HTMLFormElement>) => {
    if (disabled) return;
    e.preventDefault();
    if (input.trim()) {
      onSendMessage(input);
      setInput("");
    }
  };

  return (
    <form onSubmit={handleSubmit} className=" p-0">
      <div className="flex fixed left-1/4 w-1/2 h-[60px] mx-auto bottom-5  ">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          className=" h-full w-full  rounded-[30px] px-10 focus:outline-none bg-[#2f2f2f] placeholder-white text-white"
          placeholder="Message StreamChat"
        />
        <button
          disabled={disabled}
          type="submit"
          className={`absolute right-[10px] bottom-[10px] w-[40px] h-[40px] rounded-[20px] text-white flex items-center justify-center transition-colors ${
            disabled
              ? "bg-[#4a4a4a] cursor-not-allowed"
              : "bg-[#676767] hover:bg-[#7a7a7a]"
          }`}
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="24"
            height="24"
            fill="none"
            viewBox="0 0 24 24"
            className={disabled ? "opacity-50" : ""}
          >
            <path
              fill="currentColor"
              fillRule="evenodd"
              d="M11.394 6.68a.857.857 0 0 1 1.212 0l3.857 3.857a.857.857 0 0 1-1.212 1.212l-2.394-2.394v7.36a.857.857 0 0 1-1.714 0v-7.36l-2.394 2.394a.857.857 0 1 1-1.212-1.212z"
              clipRule="evenodd"
            />
          </svg>
        </button>
      </div>
    </form>
  );
}



================================================
FILE: stockbroker/frontend/src/components/Interrupted.tsx
================================================
import { updateState } from "@/utils/chatApi";
import { ThreadState } from "@langchain/langgraph-sdk";
import { useState } from "react";

export interface GraphInterruptProps {
  threadId: string;
  state: ThreadState<Record<string, any>>;
  setAllowNullMessage: (value: boolean) => void;
}

// The JSON to update state with if the user confirms the purchase.
const CONFIRM_PURCHASE = {
  purchaseConfirmed: true,
};
// The name of the node to update the state as
const PREPARE_PURCHASE_DETAILS_NODE = "prepare_purchase_details";

export function GraphInterrupt(props: GraphInterruptProps) {
  const [confirmed, setConfirmed] = useState(false);
  const [disabled, setDisabled] = useState(false);
  const [stateUpdated, setStateUpdated] = useState(false);

  async function callUpdateState() {
    setDisabled(true);
    await updateState(props.threadId, {
      newState: CONFIRM_PURCHASE,
      asNode: PREPARE_PURCHASE_DETAILS_NODE,
    });
    setDisabled(false);
    setStateUpdated(true);
    props.setAllowNullMessage(true);
  }

  if (stateUpdated) {
    return (
      <div className="flex flex-col w-2/3 mx-auto p-3 overflow-y-scroll">
        <p className="text-white mx-auto">State updated.</p>
      </div>
    );
  }

  return (
    <div className="flex flex-col w-2/3 mx-auto overflow-y-scroll pt-[-100px] pb-[100px]">
      <p className="text-lg text-white mb-4">
        Graph interrupted. Next: <code>{props.state.next}</code>
      </p>
      <div className="flex flex-col gap-4">
        <label className="flex items-center space-x-3 text-white">
          <input
            type="checkbox"
            checked={confirmed}
            onChange={(e) => setConfirmed(e.target.checked)}
            disabled={disabled}
            className="form-checkbox h-5 w-5 text-blue-500 rounded focus:ring-blue-500 disabled:opacity-50 cursor-pointer"
          />
          <span className={`font-medium ${disabled ? "opacity-50" : ""}`}>
            Confirm purchase
          </span>
        </label>

        <button
          onClick={callUpdateState}
          disabled={disabled || !confirmed}
          className={
            "bg-blue-500 text-white px-4 py-2 rounded-lg transition-colors duration-200 ease-in-out" +
            "hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-opacity-50" +
            "disabled:opacity-50 disabled:cursor-not-allowed"
          }
        >
          Update State
        </button>
      </div>
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/Message.tsx
================================================
import Markdown from "react-markdown";
import ToolCall from "./ToolCall";
import { ToolCall as ToolCallType } from "../types";
import { useState, useEffect } from "react";

export default function Message({
  text,
  sender,
  toolCalls,
}: {
  text: string;
  sender: string;
  toolCalls?: ToolCallType[];
}) {
  const isBot = sender === "ai";
  const [isVisible, setIsVisible] = useState(false);

  useEffect(() => {
    setIsVisible(true);
  }, []);

  return (
    <div
      className={`flex ${
        isBot ? "justify-start" : "justify-end"
      } mb-4 relative transition-opacity duration-1000 ease-in-out ${
        isVisible ? "opacity-100" : "opacity-0"
      }`}
    >
      {isBot && (
        <img
          src="/logo.jpeg"
          alt="Bot Icon"
          className="absolute left-0 top-4 w-8 h-8 rounded-full"
          style={{ transform: "translateX(-120%)" }}
        />
      )}
      <div
        className={`overflow-x-wrap break-words p-5 rounded-3xl ${
          isBot
            ? "w-full opacity-90 text-gray-200"
            : "mt-10 max-w-md text-gray-200 opacity-90"
        }`}
      >
        {toolCalls &&
          toolCalls.length > 0 &&
          toolCalls.map((toolCall) => (
            <ToolCall key={toolCall.id} {...toolCall} />
          ))}
        {isBot ? <Markdown>{text}</Markdown> : text}
      </div>
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/MessageList.tsx
================================================
import Message from "./Message";
import SkeletonMessage from "./SkeletonMessage";
import { Message as MessageType } from "../types";

export default function MessageList({
  messages,
  isLoading,
}: {
  messages: MessageType[];
  isLoading: boolean;
}) {
  return (
    <div className="pb-[100px] w-2/3 mx-auto p-10 overflow-y-scroll">
      {messages.map((message, index) => (
        <div key={index}>
          <Message
            text={message.text}
            sender={message.sender}
            toolCalls={message.toolCalls}
          />
        </div>
      ))}
      {isLoading && <SkeletonMessage />}
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/Settings.tsx
================================================
import { useState } from "react";

export type Model = "gpt-4o" | "haiku" | "gpt-4o-mini" | "sonnet-3.5";

interface SettingsProps {
  onModelChange: (model: Model) => void;
  onSystemInstructionsChange: (instructions: string) => void;
  currentModel: Model;
  currentSystemInstructions: string;
}

export default function Settings({
  onModelChange,
  onSystemInstructionsChange,
  currentModel,
  currentSystemInstructions,
}: SettingsProps) {
  const [isOpen, setIsOpen] = useState(false);
  const models: Model[] = ["gpt-4o", "haiku", "gpt-4o-mini", "sonnet-3.5"];

  return (
    <div className="absolute  right-0">
      <button
        onClick={() => setIsOpen(!isOpen)}
        className="p-2 text-xl text-white"
      >
        ⚙️
      </button>
      {isOpen && (
        <div className="absolute right-0  mt-2 w-64 bg-gray-800 rounded-md shadow-lg z-10 p-4">
          <h3 className="font-bold mb-2">Model</h3>
          {models.map((model) => (
            <button
              key={model}
              onClick={() => {
                onModelChange(model);
                setIsOpen(false);
              }}
              className={`block w-full text-left px-4 py-2 text-sm ${
                model === currentModel
                  ? "text-white bg-gray-700 font-bold"
                  : "text-gray-200 hover:bg-gray-100"
              }`}
            >
              {model}
            </button>
          ))}
          <h3 className="font-bold mt-4 mb-2">System Instructions</h3>
          <textarea
            value={currentSystemInstructions}
            onChange={(e) => onSystemInstructionsChange(e.target.value)}
            className="w-full h-12 p-2 border rounded bg-gray-700 text-sm focus:outline-none"
            placeholder="Enter system instructions..."
          />
        </div>
      )}
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/SkeletonMessage.tsx
================================================
export default function SkeletonMessage() {
  return (
    <div className="flex justify-start mb-4 relative">
      <img
        src="/logo.jpeg"
        alt="Bot Icon"
        className="absolute left-0 top-4 w-8 h-8 rounded-full"
        style={{ transform: "translateX(-120%)" }}
      />
      <div className="w-full p-5 rounded-3xl  ">
        <div className="h-4 bg-gray-600 rounded w-3/4 mb-2 animate-pulse"></div>
        <div className="h-4 bg-gray-600 rounded w-1/2 animate-pulse"></div>
      </div>
    </div>
  );
}



================================================
FILE: stockbroker/frontend/src/components/ToolCall.tsx
================================================
"use client";
import React, { useState } from "react";
import dynamic from "next/dynamic";

// Throws build errors if we try to import this normally
const ReactJson = dynamic(() => import("react-json-view"), { ssr: false });

const ToolCall = ({
  name,
  args,
  result,
}: {
  name: string;
  args: any;
  result?: any;
}) => {
  const [isResultVisible, setIsResultVisible] = useState(false);

  let parsedArgs: Record<string, any> | null = null;
  let isParsedArgsDefined = false;
  try {
    if (typeof args === "string") {
      parsedArgs = JSON.parse(args);
    } else if (typeof args === "object") {
      parsedArgs = args;
    }
    isParsedArgsDefined = true;
  } catch (_) {
    // incomplete JSON, no-op
  }

  let resultString: string | null = null;
  let resultObject: Record<string, any> | null = null;
  let isResultDefined = false;
  try {
    resultString = result;
    if (resultString) {
      isResultDefined = true;
      resultObject = JSON.parse(resultString);
      // If we're able to parse result, then it's a JSON object and we should remove the string
      // so it's not able to be duplicated in the rendered UI.
      resultString = null;
    }
  } catch (_) {
    // incomplete JSON, no-op
  }

  return (
    <div className="bg-[#3a3a3a] text-white p-4 rounded-lg mb-2 text-sm relative flex flex-col gap-1">
      <div className="w-full mb-2 flex justify-between items-center">
        <div className="flex flex-row items-center justify-start gap-2">
          <span className="text-gray-400">Tool Call:</span>
          <p className="text-small opacity-80">{name}</p>
        </div>
        {isResultDefined && (
          <button
            onClick={() => setIsResultVisible(!isResultVisible)}
            className="text-gray-400 hover:text-gray-300 focus:outline-none"
          >
            {isResultVisible ? "Hide result" : "Show result"}
          </button>
        )}
      </div>

      <div className="flex flex-col gap-1">
        <p className="text-gray-400">Arguments:</p>
        <span>
          {isParsedArgsDefined && parsedArgs ? (
            <ReactJson
              displayObjectSize={false}
              style={{ backgroundColor: "transparent" }}
              displayDataTypes={false}
              quotesOnKeys={false}
              enableClipboard={false}
              name={false}
              src={parsedArgs}
              theme="tomorrow"
            />
          ) : typeof args === "string" ? (
            <p>{args}</p>
          ) : (
            <code>{JSON.stringify(args, null, 2)}</code>
          )}
        </span>
      </div>

      {isResultDefined && (
        <div
          className={`mt-2 overflow-y-scroll transition-all duration-500 ease-in-out ${
            isResultVisible ? "max-h-96" : "max-h-0"
          }`}
        >
          <span>
            <p className="text-gray-400">Result:</p>
            <div>
              {resultObject && !resultString ? (
                <ReactJson
                  displayObjectSize={false}
                  style={{
                    backgroundColor: "transparent",
                  }}
                  displayDataTypes={false}
                  quotesOnKeys={false}
                  enableClipboard={false}
                  name={false}
                  src={resultObject}
                  theme="tomorrow"
                />
              ) : null}
              {resultString && !resultObject && <p>{resultString}</p>}
            </div>
          </span>
        </div>
      )}
    </div>
  );
};

export default ToolCall;



================================================
FILE: stockbroker/frontend/src/utils/chatApi.ts
================================================
import { ThreadState, Client } from "@langchain/langgraph-sdk";

const createClient = () => {
  const apiUrl = process.env.NEXT_PUBLIC_API_URL ?? "http://localhost:3000/api";
  return new Client({
    apiUrl,
  });
};

export const createAssistant = async (graphId: string) => {
  const client = createClient();
  return client.assistants.create({ graphId });
};

export const createThread = async () => {
  const client = createClient();
  return client.threads.create();
};

export const getThreadState = async (
  threadId: string
): Promise<ThreadState<Record<string, any>>> => {
  const client = createClient();
  return client.threads.getState(threadId);
};

export const updateState = async (
  threadId: string,
  fields: {
    newState: Record<string, any>;
    asNode?: string;
  }
) => {
  const client = createClient();
  return client.threads.updateState(threadId, {
    values: fields.newState,
    asNode: fields.asNode,
  });
};

export const sendMessage = async (params: {
  threadId: string;
  assistantId: string;
  message: string | null;
  model: string;
  userId: string;
  systemInstructions: string;
}) => {
  const client = createClient();

  let input: Record<string, any> | null = null;
  if (params.message !== null) {
    input = {
      messages: [
        {
          role: "human",
          content: params.message,
        },
      ],
      userId: params.userId,
    };
  }
  const config = {
    configurable: {
      model_name: params.model,
      system_instructions: params.systemInstructions,
    },
  };

  return client.runs.stream(params.threadId, params.assistantId, {
    input,
    config,
    streamMode: "messages",
  });
};



================================================
FILE: stockbroker/frontend/src/utils/cookies.ts
================================================
import Cookies from "js-cookie";

export function getCookie(key: string) {
  if (typeof window === "undefined") return null;
  return Cookies.get(key) ?? null;
}

export function setCookie(key: string, value: string) {
  if (typeof window === "undefined") return null;
  Cookies.set(key, value);
}



================================================
FILE: stockbroker/frontend/src/utils/shadcnUtils.ts
================================================
import { clsx, type ClassValue } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: stockbroker/frontend/src/utils/streamHandler.ts
================================================
import { Message, ToolCall } from "../types";

export const handleStreamEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>
) => {
  // let currentMessageId: string | undefined;

  if (event.event === "messages/partial") {
    event.data.forEach((dataItem: any) => {
      if (
        dataItem.type === "ai" &&
        Array.isArray(dataItem.tool_calls) &&
        dataItem.tool_calls.length > 0
      ) {
        setMessages((prevMessages) => {
          const lastMessage = prevMessages[prevMessages.length - 1];
          if (lastMessage && lastMessage.sender === "ai") {
            // Merge new tool calls with existing ones
            const mergedToolCalls = [
              ...(lastMessage.toolCalls || []),
              ...dataItem.tool_calls.filter(
                (newTc: ToolCall) =>
                  !lastMessage.toolCalls?.some(
                    (existingTc) => existingTc.id === newTc.id
                  )
              ),
            ].map((tc: ToolCall) => {
              const updatedTc = dataItem.tool_calls.find(
                (newTc: ToolCall) => newTc.id === tc.id
              );
              return updatedTc ? { ...tc, ...updatedTc } : tc;
            });

            return [
              ...prevMessages.slice(0, -1),
              {
                ...lastMessage,
                toolCalls: mergedToolCalls,
              },
            ];
          } else {
            // If the last message was not from AI, add a new message
            return [
              ...prevMessages,
              {
                text: "",
                sender: "ai",
                toolCalls: dataItem.tool_calls,
                id: dataItem.id,
              },
            ];
          }
        });
      } else if (dataItem.content) {
        setMessages((prevMessages) => {
          const lastMessage = prevMessages[prevMessages.length - 1];
          if (lastMessage && lastMessage.sender === "ai") {
            return [
              ...prevMessages.slice(0, -1),
              {
                ...lastMessage,
                text: dataItem.content,
                toolCalls: lastMessage.toolCalls || [],
              },
            ];
          } else {
            return [
              ...prevMessages,
              {
                text: dataItem.content,
                sender: "ai",
                toolCalls: [],
                id: dataItem.id,
              },
            ];
          }
        });
      }
    });
  } else if (event.event === "messages/complete") {
    const dataItem = event.data[event.data.length - 1];
    if (dataItem.type === "tool") {
      // Handle tool call completion
      const toolCall: Partial<ToolCall> = {
        id: dataItem.tool_call_id,
        name: dataItem.name,
        result: dataItem.content,
      };

      // Only set args if it's truthy
      if (dataItem.artifact) {
        toolCall.args = dataItem.artifact;
      }

      setMessages((prevMessages) => {
        const lastMessage = prevMessages[prevMessages.length - 1];
        if (lastMessage && lastMessage.sender === "ai") {
          return [
            ...prevMessages.slice(0, -1),
            {
              ...lastMessage,
              toolCalls: lastMessage.toolCalls?.map((tc) =>
                tc.id === toolCall.id ? { ...tc, ...toolCall } : tc
              ) || [toolCall as ToolCall],
            },
          ];
        } else {
          return [
            ...prevMessages,
            {
              text: "",
              sender: "ai",
              toolCalls: [toolCall as ToolCall],
              id: dataItem.id,
            },
          ];
        }
      });
    } else if (dataItem.type === "ai" && dataItem.content) {
      setMessages((prevMessages) => {
        const messageExists = prevMessages.some(
          (msg) => msg.id === dataItem.id
        );
        // Message already exists, don't add it again
        if (messageExists) {
          return prevMessages;
        }

        const messageStreamed = prevMessages.find((msg) =>
          dataItem.content.startsWith(msg.text)
        );

        if (messageStreamed) {
          // Message has already partially been streamed, update it
          return prevMessages.map((msg) => {
            if (msg.id === messageStreamed.id) {
              return { ...messageStreamed, text: dataItem.content };
            }
            return msg;
          });
        }

        return [
          ...prevMessages,
          { id: dataItem.id, text: dataItem.content, sender: "ai" },
        ];
      });
    }
  }
};



================================================
FILE: streaming_messages/README.md
================================================
# Streaming Message Types

This project contains four TypeScript files, each containing calls to a LangGraph Cloud deployment, demonstrating the different ways to stream messages and data from the server to the client.
This ranges from streaming only messages updated in the state, to streaming every event which occurs throughout the duration of your run.

This repository contains two directories: `runnable` and `langgraph_sdk`.

The `runnable` directory contains a simple LangGraph implementation, and files to stream that graph using runnable code.

The `langgraph_sdk` contains code to invoke a deployed LangGraph Cloud instance using the LangChain SDK.

## [YouTube Video](https://youtu.be/wjn5tFbLgwA)

## Setup

To setup the streaming message types project, install the dependencies:

```bash
yarn install
```

## Environment variables

The streaming messages project only requires your LangChain API key, the LangGraph Cloud deployment URL, and the name of your graph.

Once you have these, create a `.env` file in this directory and add the following:

```bash
LANGGRAPH_API_URL=http://localhost:8123 # Or your production URL
LANGCHAIN_API_KEY=YOUR_API_KEY
NEXT_PUBLIC_LANGGRAPH_GRAPH_ID=YOUR_GRAPH_ID
```

## Message Types

### `events`

The "events" stream mode is the most comprehensive streaming mode. It streams back every single event yielded by the run, providing the most detailed insight into the execution process.

#### What data is returned:

The `events` stream mode yields a new event for every single action taken during your run. Each streamed chunk contains two key fields:

- `event`: The type of event yielded. Formatted as `on_[runnable type]_(start|stream|end)`. For example:

  - `on_chain_start`: Indicates the start of a chain execution.
  - `on_chat_model_stream`: Represents streaming output from a language model.
  - `on_chain_end`: Signals the end of a chain execution.

- `data`: The data received by that event. This may include:
  - `input`: Data passed into the event.
  - `output`: Data returned from the event.
  - `chunk`: Any data yielded (streamed) while the event is still in progress.

#### Use case:

The `events` stream mode is ideal for applications requiring fine-grained insights into the exact steps and actions taken during a run. It's particularly useful for:

- Generative UI applications where real-time updates reflecting server-side actions are crucial.
- Debugging complex workflows to understand the sequence and timing of events.
- Building detailed logging or monitoring systems for AI-powered applications.

Key benefits:

- Comprehensive visibility: Captures every event in the run, from start to finish.
- Real-time insights: Allows for immediate reaction to each step in the process.
- Detailed control: Enables fine-grained control over UI updates and application logic based on specific events.

This mode is perfect when you need to create highly responsive and transparent applications that can react to and display the intricacies of the AI's decision-making process in real-time.

### `messages`

The "messages" stream mode focuses on chat messages. It streams chat messages when:

- New messages are added to the thread state
- Updates are made to existing messages with token-by-token streaming

#### What data is returned:

Chat messages will only ever be returned if using this stream model. It does not include the full chat history.

#### Use case:

The "messages" stream mode is best suited for most chatbot applications where chat messages are exchanged between the user and the assistant. A common use case would be a simple chat bot where only human and assistant messages are rendered on the client.

Key benefits:

- Focused data: The API only responds when a chat message is updated in the thread state.
- Efficient: Non-chat message updates to the thread state are not streamed back.
- Real-time interaction: Allows for token-by-token streaming of model responses, enabling a more responsive user experience.

This mode is ideal when you want to create a straightforward chat interface without the need for additional state information or fine-grained event tracking.

### `updates`

The "updates" stream mode is selective in what it returns. It streams:

- Only the updates returned from a node
- Specific key updates made through the `.updateState({ ... })` method

#### What data is returned:

Data is only streamed back in two scenarios:

1. When a node finishes and returns values: The stream sends only the data returned from that node, nested inside an object where the key is the node's name.
2. When the `.updateState({ ... })` method is called: The stream sends back only the values passed to the `updateState` call.

The data returned can be of any type, as the `updates` mode focuses solely on the fact that an update was made, regardless of the data type.

#### Use case:

The "updates" stream mode is ideal when your client needs to know only about specific changes or updates made during the process, without requiring knowledge of the entire thread state.

Key benefits:

- Focused updates: Only streams data when specific updates occur.
- Efficient: Doesn't send unnecessary information, reducing data transfer.
- Flexible: Can handle various types of data updates.

This mode is perfect for applications like notification systems, where the primary task is to display changes and updates without needing the context of the full thread state.
It's also useful for scenarios where you want to track specific milestones or changes in your process without the overhead of streaming all events or the entire state.

### `values`

The "values" stream mode provides a comprehensive view of the thread state. It streams:

- The entire thread state any time it changes
- Updates or additions to the thread state

#### What data is returned:

The `values` stream mode sends data through the stream anytime a change is made to the overall thread state. When a change occurs, this mode responds with the entire thread state, including:

- The recent update
- All existing fields, even if they weren't modified in this event

This means that even if a state field was not updated during a particular event, it will still be included in the streamed data, as the mode returns the complete state.

#### Use case:

The `values` stream mode is ideal for applications that require a real-time, holistic view of the thread state. It's particularly useful in scenarios such as:

- Analytics dashboards displaying the current state of a thread
- Applications needing to show and update all state fields upon any change
- Systems that require constant synchronization between server and client states

Key benefits:

- Comprehensive updates: Provides the full thread state with every change
- Real-time synchronization: Ensures the client always has the most up-to-date information
- Simplifies state management: Eliminates the need for partial state updates on the client side

This mode is perfect when your application needs to know the current state of the thread and be updated whenever it changes.
It's especially useful for systems that are constantly updating in the background, where the client needs to always know and display the current state in its entirety.

## Running the examples

Each of the examples in this project has a corresponding script which can be used to invoke the example.
The following scripts are available:

```bash
yarn start:events
yarn start:messages
yarn start:updates
yarn start:values
```



================================================
FILE: streaming_messages/langgraph.json
================================================
{
  "node_version": "20",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "streaming_messages": "./src/runnable/graph.ts:graph"
  },
  "env": ".env"
}




================================================
FILE: streaming_messages/package.json
================================================
{
  "name": "human-in-the-loop",
  "description": "LangGraph.js examples of human in the loop graphs.",
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "build": "yarn tsc --project tsconfig.json --outDir dist",
    "start:events": "tsx --experimental-wasm-modules -r dotenv/config src/runnable/stream_events.ts",
    "start:messages": "tsx --experimental-wasm-modules -r dotenv/config src/runnable/stream_messages.ts",
    "start:updates": "tsx --experimental-wasm-modules -r dotenv/config src/runnable/stream_updates.ts",
    "start:values": "tsx --experimental-wasm-modules -r dotenv/config src/runnable/stream_values.ts",
    "lint": "eslint src",
    "lint:fix": "yarn lint --fix",
    "format": "prettier --write \"**/*.ts\"",
    "format:check": "prettier --check \"**/*.ts\""
  },
  "author": "Brace Sproul",
  "license": "MIT",
  "dependencies": {
    "@langchain/community": "^0.3.34",
    "@langchain/core": "^0.3.42",
    "@langchain/langgraph": "^0.2.54",
    "@langchain/langgraph-sdk": "^0.0.52",
    "@langchain/openai": "^0.4.4"
  },
  "devDependencies": {
    "@tsconfig/recommended": "^1.0.2",
    "@types/node": "^22.5.3",
    "@typescript-eslint/eslint-plugin": "^5.51.0",
    "@typescript-eslint/parser": "^5.51.0",
    "dotenv": "^16.0.3",
    "eslint": "^8.33.0",
    "eslint-config-airbnb-base": "^15.0.0",
    "eslint-config-prettier": "^8.6.0",
    "eslint-plugin-import": "^2.27.5",
    "eslint-plugin-prettier": "^4.2.1",
    "eslint-plugin-unused-imports": "^3.0.0",
    "prettier": "^2.8.3",
    "tsx": "^3.12.3",
    "typescript": "^5.0.0"
  },
  "resolutions": {
    "@langchain/core": "0.2.31"
  }
}



================================================
FILE: streaming_messages/tsconfig.json
================================================
{
  "extends": "@tsconfig/recommended",
  "compilerOptions": {
    "outDir": "dist",
    "lib": [
      "ES2021",
      "ES2022.Object",
      "DOM"
    ],
    "target": "ES2021",
    "module": "nodenext",
    "sourceMap": true,
    "allowSyntheticDefaultImports": true,
    "baseUrl": "./src",
    "declaration": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noUnusedParameters": true,
    "useDefineForClassFields": true,
    "strictPropertyInitialization": false
  },
  "exclude": [
    "node_modules/",
    "dist/",
    "tests/"
  ],
  "include": [
    "./src"
  ]
}



================================================
FILE: streaming_messages/.env.example
================================================
# ------------------LangSmith tracing------------------
LANGCHAIN_API_KEY=
LANGCHAIN_TRACING_V2=true
LANGCHAIN_CALLBACKS_BACKGROUND=true
# -----------------------------------------------------

OPENAI_API_KEY=



================================================
FILE: streaming_messages/src/utils.ts
================================================
export const logMessageEvent = (
  response: {
    event: string;
    data: any;
  },
  extra: {
    toolCallLogged: boolean;
    contentLogged: boolean;
  }
) => {
  const { event, data } = response;
  let { toolCallLogged, contentLogged } = extra;
  if (
    !Array.isArray(data) ||
    data.length === 0 ||
    !("content" in data[0] || "type" in data[0])
  ) {
    console.log("Non message event:", event);
    console.log("\n---\n");
  } else {
    data.forEach((msg: any) => {
      if (!msg.content && msg.tool_calls?.length) {
        if (!toolCallLogged) {
          console.log("\n---TOOL CALL---\n");
          toolCallLogged = true;
        }
        console.dir({
          type: msg.type,
          tool_calls: msg.tool_calls[0],
        });
      } else if (msg.content && msg.tool_calls?.length) {
        if (!toolCallLogged) {
          console.log("\n---TOOL CALL---\n");
          toolCallLogged = true;
        }
        if (!contentLogged) {
          console.log("\n---CONTENT---\n");
          contentLogged = true;
        }
        console.dir({
          type: msg.type,
          content: msg.content,
          tool_calls: msg.tool_calls[0],
        });
      } else if (msg.content) {
        if (!contentLogged) {
          console.log("\n---CONTENT---\n");
          contentLogged = true;
        }
        console.dir({
          type: msg.type,
          content: msg.content,
        });
      }
    });
    console.log("\n---\n");
  }

  return {
    toolCallLogged,
    contentLogged,
  };
};

export const logUpdateEvent = (response: { event: string; data: any }) => {
  const { event, data } = response;
  if (event !== "updates") {
    console.log("Event: ", event);
    return;
  }
  const node = Object.keys(data)[0];
  const nodeReturnData = data[node];
  if (!("messages" in nodeReturnData)) {
    return;
  }
  const { messages } = nodeReturnData;
  console.log("\nUpdate from node:", node);
  logMessageEvent(
    {
      event,
      data: messages,
    },
    {
      toolCallLogged: true, // Don't log these extras
      contentLogged: true,
    }
  );
};

export const logValuesEvent = (response: { event: string; data: any }) => {
  const { event, data } = response;
  if (event !== "values") {
    console.log("Event: ", event);
    return;
  }
  if (!("messages" in data)) {
    return;
  }
  const { messages } = data;
  console.log("\n---NEW VALUES---\n");
  logMessageEvent(
    {
      event,
      data: messages,
    },
    {
      toolCallLogged: true, // Don't log these extras
      contentLogged: true,
    }
  );
};



================================================
FILE: streaming_messages/src/langgraph_sdk/stream_events.ts
================================================
import { Client } from "@langchain/langgraph-sdk";

const client = new Client({
  apiKey: process.env.LANGCHAIN_API_KEY,
  apiUrl: process.env.LANGGRAPH_API_URL,
});

const thread = await client.threads.create();
const threadId = thread.thread_id;
const assistant = await client.assistants.create({
  graphId: process.env.LANGGRAPH_GRAPH_ID as string,
});
const assistantId = assistant.assistant_id;

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const stream = client.runs.stream(threadId, assistantId, {
  input,
  streamMode: "events",
});

for await (const event of stream) {
  console.log({
    event: event.event,
    data: event.data,
  });
}



================================================
FILE: streaming_messages/src/langgraph_sdk/stream_messages.ts
================================================
import { Client } from "@langchain/langgraph-sdk";
import { logMessageEvent } from "utils.js";

const client = new Client({
  apiKey: process.env.LANGCHAIN_API_KEY,
  apiUrl: process.env.LANGGRAPH_API_URL,
});

const thread = await client.threads.create();
const threadId = thread.thread_id;
const assistant = await client.assistants.create({
  graphId: process.env.LANGGRAPH_GRAPH_ID as string,
});
const assistantId = assistant.assistant_id;

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const stream = client.runs.stream(threadId, assistantId, {
  input,
  streamMode: "messages",
});

let toolCallLogged = false;
let contentLogged = false;

for await (const event of stream) {
  const res = logMessageEvent(event, {
    toolCallLogged,
    contentLogged,
  });
  toolCallLogged = res.toolCallLogged;
  contentLogged = res.contentLogged;
}



================================================
FILE: streaming_messages/src/langgraph_sdk/stream_updates.ts
================================================
import { Client } from "@langchain/langgraph-sdk";
import { logUpdateEvent } from "utils.js";

const client = new Client({
  apiKey: process.env.LANGCHAIN_API_KEY,
  apiUrl: process.env.LANGGRAPH_API_URL,
});

const thread = await client.threads.create();
const threadId = thread.thread_id;
const assistant = await client.assistants.create({
  graphId: process.env.LANGGRAPH_GRAPH_ID as string,
});
const assistantId = assistant.assistant_id;

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const stream = client.runs.stream(threadId, assistantId, {
  input,
  streamMode: "updates",
});

for await (const event of stream) {
  logUpdateEvent(event);
}



================================================
FILE: streaming_messages/src/langgraph_sdk/stream_values.ts
================================================
import { Client } from "@langchain/langgraph-sdk";
import { logValuesEvent } from "utils.js";

const client = new Client({
  apiKey: process.env.LANGCHAIN_API_KEY,
  apiUrl: process.env.LANGGRAPH_API_URL,
});

const thread = await client.threads.create();
const threadId = thread.thread_id;
const assistant = await client.assistants.create({
  graphId: process.env.LANGGRAPH_GRAPH_ID as string,
});
const assistantId = assistant.assistant_id;

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const stream = client.runs.stream(threadId, assistantId, {
  input,
  streamMode: "values",
});

for await (const event of stream) {
  logValuesEvent(event);
}



================================================
FILE: streaming_messages/src/runnable/graph.ts
================================================
import { ToolNode } from "@langchain/langgraph/prebuilt";
import {
  END,
  MemorySaver,
  MessagesAnnotation,
  START,
  StateGraph,
} from "@langchain/langgraph";
import { AIMessage, BaseMessage } from "@langchain/core/messages";
import { ChatOpenAI } from "@langchain/openai";
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});

const webSearchTool = new TavilySearchResults({
  maxResults: 4,
});
const tools = [webSearchTool];

const toolNode = new ToolNode(tools);

const callModel = async (state: typeof MessagesAnnotation.State) => {
  const { messages } = state;

  const llmWithTools = llm.bindTools(tools);
  const result = await llmWithTools.invoke(messages);
  return { messages: [result] };
};

const shouldContinue = (state: typeof MessagesAnnotation.State) => {
  const { messages } = state;

  const lastMessage = messages[messages.length - 1];
  if (
    lastMessage._getType() !== "ai" ||
    !(lastMessage as AIMessage).tool_calls?.length
  ) {
    // LLM did not call any tools, or it's not an AI message, so we should end.
    return END;
  }
  return "tools";
};

/**
 * MessagesAnnotation is a pre-built state annotation imported from @langchain/langgraph.
 * It is the same as the following annotation:
 *
 * ```typescript
 * const MessagesAnnotation = Annotation.Root({
 *   messages: Annotation<BaseMessage[]>({
 *     reducer: messagesStateReducer,
 *     default: () => [systemMessage],
 *   }),
 * });
 * ```
 */
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)
  .addEdge(START, "agent")
  .addNode("tools", toolNode)
  .addEdge("tools", "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END]);

export const graph = workflow.compile({
  // The LangGraph Studio/Cloud API will automatically add a checkpointer
  // only uncomment if running locally
  checkpointer: new MemorySaver(),
});



================================================
FILE: streaming_messages/src/runnable/stream_events.ts
================================================
import { graph } from "./graph.js";

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const config = {
  configurable: {
    thread_id: "stream_events",
  },
  version: "v2" as const,
};

const stream = graph.streamEvents(input, config);

for await (const event of stream) {
  console.dir(
    {
      event: event.event,
      data: event.data,
    },
    { depth: 3 }
  );
}



================================================
FILE: streaming_messages/src/runnable/stream_messages.ts
================================================
import { graph } from "./graph.js";

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const config = {
  configurable: {
    thread_id: "stream_messages",
  },
};

const stream = await graph.stream(input, config);

for await (const event of stream) {
  console.log(event);
}



================================================
FILE: streaming_messages/src/runnable/stream_updates.ts
================================================
import { graph } from "./graph.js";

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const config = {
  configurable: {
    thread_id: "stream_updates",
  },
  streamMode: "updates" as const,
};

const stream = await graph.stream(input, config);

for await (const event of stream) {
  console.log(event);
}



================================================
FILE: streaming_messages/src/runnable/stream_values.ts
================================================
import { graph } from "./graph.js";

const input = {
  messages: {
    role: "user",
    content: "What is the current stock price of $AAPL?",
  },
};

const config = {
  configurable: {
    thread_id: "stream_values",
  },
  streamMode: "values" as const,
};

const stream = await graph.stream(input, config);

for await (const event of stream) {
  console.log(event);
}



================================================
FILE: streaming_messages_frontend/README.md
================================================
# Streaming Messages

This project contains a Next.js app, with API routes to hit a LangGraph Cloud deployment and demonstrate exactly how the different streaming types work.
To change the streaming type, click on the settings (⚙️) icon in the top right corner of the app and select the desired streaming type.

## [YouTube Video](https://youtu.be/wjn5tFbLgwA)

## Setup

To setup the project, install the dependencies:

```bash
yarn install
```

## Environment variables

The streaming messages project only requires your LangChain API key, the LangGraph Cloud deployment URL, and the name of your graph.

Once you have these, create a `.env` file in this directory and add the following:

```bash
LANGGRAPH_API_URL=http://localhost:8123 # Or your production URL
LANGCHAIN_API_KEY=YOUR_API_KEY
NEXT_PUBLIC_LANGGRAPH_GRAPH_ID=YOUR_GRAPH_ID
```



================================================
FILE: streaming_messages_frontend/next.config.mjs
================================================
/** @type {import('next').NextConfig} */
const nextConfig = {};

export default nextConfig;



================================================
FILE: streaming_messages_frontend/package.json
================================================
{
  "name": "streaming_chat_frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "format": "prettier --config .prettierrc --write \"src\""
  },
  "dependencies": {
    "@langchain/langgraph-sdk": "^0.0.52",
    "js-cookie": "^3.0.5",
    "next": "14.2.7",
    "react": "^18",
    "react-dom": "^18",
    "react-json-view": "^1.21.3",
    "react-markdown": "^9.0.1",
    "tailwind-scrollbar-hide": "^1.1.7",
    "uuid": "^10.0.0"
  },
  "devDependencies": {
    "@types/js-cookie": "^3.0.6",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "@types/uuid": "^10.0.0",
    "eslint": "^8",
    "eslint-config-next": "14.2.7",
    "postcss": "^8",
    "prettier": "^3.3.3",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}



================================================
FILE: streaming_messages_frontend/postcss.config.mjs
================================================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;



================================================
FILE: streaming_messages_frontend/tailwind.config.ts
================================================
import type { Config } from "tailwindcss";

const config: Config = {
  content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
    extend: {
      backgroundImage: {
        "gradient-radial": "radial-gradient(var(--tw-gradient-stops))",
        "gradient-conic":
          "conic-gradient(from 180deg at 50% 50%, var(--tw-gradient-stops))",
      },
    },
  },
  plugins: [require("tailwind-scrollbar-hide")],
};
export default config;



================================================
FILE: streaming_messages_frontend/tsconfig.json
================================================
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: streaming_messages_frontend/.env.example
================================================
LANGGRAPH_API_URL=http://localhost:8123 # Or your production URL
LANGCHAIN_API_KEY=YOUR_API_KEY
NEXT_PUBLIC_LANGGRAPH_GRAPH_ID=YOUR_GRAPH_ID


================================================
FILE: streaming_messages_frontend/.eslintrc.json
================================================
{
  "extends": "next/core-web-vitals"
}



================================================
FILE: streaming_messages_frontend/.prettierrc
================================================
{
  "$schema": "https://json.schemastore.org/prettierrc",
  "printWidth": 80,
  "tabWidth": 2,
  "useTabs": false,
  "semi": true,
  "singleQuote": false,
  "quoteProps": "as-needed",
  "jsxSingleQuote": false,
  "trailingComma": "es5",
  "bracketSpacing": true,
  "arrowParens": "always",
  "requirePragma": false,
  "insertPragma": false,
  "proseWrap": "preserve",
  "htmlWhitespaceSensitivity": "css",
  "vueIndentScriptAndStyle": false,
  "endOfLine": "lf"
}



================================================
FILE: streaming_messages_frontend/src/constants.ts
================================================
export const ASSISTANT_ID_COOKIE = "ls_assistant_id";



================================================
FILE: streaming_messages_frontend/src/types.ts
================================================
export type Message = {
  id: string;
  text?: string;
  rawResponse?: Record<string, any>;
  sender: string;
  toolCalls?: ToolCall[];
};

export interface ToolCall {
  id: string;
  name: string;
  args: string;
  result?: any;
}

export type Model = "gpt-4o-mini" | string; // Add other model options as needed



================================================
FILE: streaming_messages_frontend/src/app/globals.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --foreground-rgb: 0, 0, 0;
  --background-start-rgb: 214, 219, 220;
  --background-end-rgb: 255, 255, 255;
}

@media (prefers-color-scheme: dark) {
  :root {
    --foreground-rgb: 255, 255, 255;
    --background-start-rgb: 0, 0, 0;
    --background-end-rgb: 0, 0, 0;
  }
}
*::-webkit-scrollbar {
  display: none;
}

body {
  color: rgb(var(--foreground-rgb));
  background: linear-gradient(
      to bottom,
      transparent,
      rgb(var(--background-end-rgb))
    )
    rgb(var(--background-start-rgb));
}

a {
  color: rgb(33, 118, 246);
}

@layer utilities {
  .text-balance {
    text-wrap: balance;
  }
  .no-scrollbar::-webkit-scrollbar {
    display: none;
  }

  .no-scrollbar {
    -ms-overflow-style: none; /* IE and Edge */
    scrollbar-width: none; /* Firefox */
  }
}



================================================
FILE: streaming_messages_frontend/src/app/layout.tsx
================================================
import type { Metadata } from "next";
import { Inter } from "next/font/google";
import "./globals.css";

const inter = Inter({ subsets: ["latin"] });

export const metadata: Metadata = {
  title: "Streaming UI chat",
  description: "Streaming UI chat",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={inter.className}>{children}</body>
    </html>
  );
}



================================================
FILE: streaming_messages_frontend/src/app/page.tsx
================================================
import ChatInterface from "../components/ChatInterface";

export default function Home() {
  return (
    <main className="h-screen bg-[#212121]">
      <ChatInterface />
    </main>
  );
}



================================================
FILE: streaming_messages_frontend/src/app/api/[..._path]/route.ts
================================================
import { NextRequest, NextResponse } from "next/server";

export const runtime = "edge";

function getCorsHeaders() {
  return {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "GET, POST, PUT, PATCH, DELETE, OPTIONS",
    "Access-Control-Allow-Headers": "*",
  };
}

async function handleRequest(req: NextRequest, method: string) {
  try {
    const path = req.nextUrl.pathname.replace(/^\/?api\//, "");
    const url = new URL(req.url);
    const searchParams = new URLSearchParams(url.search);
    searchParams.delete("_path");
    searchParams.delete("nxtP_path");
    const queryString = searchParams.toString()
      ? `?${searchParams.toString()}`
      : "";

    const options: RequestInit = {
      method,
      headers: {
        "x-api-key": process.env.LANGCHAIN_API_KEY || "",
      },
    };

    if (["POST", "PUT", "PATCH"].includes(method)) {
      options.body = await req.text();
    }

    const res = await fetch(
      `${process.env.LANGGRAPH_API_URL}/${path}${queryString}`,
      options
    );

    return new NextResponse(res.body, {
      status: res.status,
      statusText: res.statusText,
      headers: {
        ...res.headers,
        ...getCorsHeaders(),
      },
    });
  } catch (e: any) {
    return NextResponse.json({ error: e.message }, { status: e.status ?? 500 });
  }
}

export const GET = (req: NextRequest) => handleRequest(req, "GET");
export const POST = (req: NextRequest) => handleRequest(req, "POST");
export const PUT = (req: NextRequest) => handleRequest(req, "PUT");
export const PATCH = (req: NextRequest) => handleRequest(req, "PATCH");
export const DELETE = (req: NextRequest) => handleRequest(req, "DELETE");

// Add a new OPTIONS handler
export const OPTIONS = () => {
  return new NextResponse(null, {
    status: 204,
    headers: {
      ...getCorsHeaders(),
    },
  });
};



================================================
FILE: streaming_messages_frontend/src/components/ChatInterface.tsx
================================================
"use client";

import { useState, useEffect, useRef } from "react";
import { v4 as uuidv4 } from "uuid";
import MessageList from "./MessageList";
import InputArea from "./InputArea";
import HomeComponent from "./HomeComponent";
import Settings, { StreamMode } from "./Settings";
import { Message, Model } from "../types";
import { handleStreamEvent } from "../utils/streamHandler";
import {
  createAssistant,
  createThread,
  getThreadState,
  sendMessage,
} from "../utils/chatApi";
import { ASSISTANT_ID_COOKIE } from "@/constants";
import { getCookie, setCookie } from "@/utils/cookies";
import { ThreadState } from "@langchain/langgraph-sdk";
import { GraphInterrupt } from "./Interrupted";

export default function ChatInterface() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [threadId, setThreadId] = useState<string | null>(null);
  const [assistantId, setAssistantId] = useState<string | null>(null);
  const [model, setModel] = useState<Model>("gpt-4o-mini" as Model);
  const [streamMode, setStreamMode] = useState<StreamMode>("messages");
  const [userId, setUserId] = useState<string>("");
  const [systemInstructions, setSystemInstructions] = useState<string>("");
  const [isLoading, setIsLoading] = useState(false);
  const [threadState, setThreadState] =
    useState<ThreadState<Record<string, any>>>();
  const [graphInterrupted, setGraphInterrupted] = useState(false);
  const [allowNullMessage, setAllowNullMessage] = useState(false);

  const messageListRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    const initializeChat = async () => {
      let assistantId = getCookie(ASSISTANT_ID_COOKIE);
      if (!assistantId) {
        const assistant = await createAssistant(
          process.env.NEXT_PUBLIC_LANGGRAPH_GRAPH_ID as string
        );
        assistantId = assistant.assistant_id as string;
        setCookie(ASSISTANT_ID_COOKIE, assistantId);
        setAssistantId(assistantId);
      }

      const { thread_id } = await createThread();
      setThreadId(thread_id);
      setAssistantId(assistantId);
      setUserId(uuidv4());
    };

    initializeChat();
  }, []);

  useEffect(() => {
    if (messageListRef.current) {
      messageListRef.current.scrollTop = messageListRef.current.scrollHeight;
    }
  }, [messages]);

  const handleSendMessage = async (message: string | null) => {
    const messageId = uuidv4();
    if (message !== null) {
      setMessages([
        ...messages,
        { text: message, sender: "user", id: messageId },
      ]);
    }

    if (!threadId) {
      console.error("Thread ID is not available");
      return;
    }
    if (!assistantId) {
      console.error("Assistant ID is not available");
      return;
    }

    try {
      setIsLoading(true);
      setThreadState(undefined);
      setGraphInterrupted(false);
      setAllowNullMessage(false);
      const response = await sendMessage({
        threadId,
        assistantId,
        message,
        messageId,
        model,
        userId,
        systemInstructions,
        streamMode,
      });

      for await (const chunk of response) {
        handleStreamEvent(chunk, setMessages, streamMode);
      }

      // Fetch the current state of the thread
      const currentState = await getThreadState(threadId);
      setThreadState(currentState);
      if (currentState.next.length) {
        setGraphInterrupted(true);
      }
      setIsLoading(false);
    } catch (error) {
      console.error("Error streaming messages:", error);
      setIsLoading(false);
    }
  };

  return (
    <div className="w-full h-screen bg-[#212121] overflow-hidden rounded-lg shadow-md">
      <Settings
        onModelChange={setModel}
        onSystemInstructionsChange={setSystemInstructions}
        currentModel={model as any}
        currentSystemInstructions={systemInstructions}
        onStreamModeChange={setStreamMode}
        currentStreamMode={streamMode}
      />
      {messages.length === 0 ? (
        <HomeComponent onMessageSelect={handleSendMessage} />
      ) : (
        <div ref={messageListRef} className="overflow-y-auto h-screen">
          <MessageList messages={messages} />
          {!!graphInterrupted && !!threadState && !!threadId ? (
            <div className="flex items-center justify-start w-2/3 mx-auto">
              <GraphInterrupt
                setAllowNullMessage={setAllowNullMessage}
                threadId={threadId}
                state={threadState}
              />
            </div>
          ) : null}
          {allowNullMessage && (
            <div className="flex flex-col w-2/3 mx-auto overflow-y-scroll pb-[100px]">
              <button
                onClick={async () => handleSendMessage(null)}
                disabled={isLoading}
                className="bg-blue-500 text-white px-4 py-2 rounded-lg mt-2 max-w-[400px] mx-auto"
              >
                Continue
              </button>
            </div>
          )}
        </div>
      )}
      <InputArea onSendMessage={handleSendMessage} />
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/HomeComponent.tsx
================================================
import React from "react";
import Image from "next/image";

const exampleMessages = [
  "What're some facts about Google?",
  "How much revenue did Apple make last year?",
  "Is McDonald's profitable?",
  "What's the current stock price of Tesla?",
];

const HomeComponent: React.FC<{
  onMessageSelect: (message: string) => void;
}> = ({ onMessageSelect }) => {
  return (
    <div className="flex flex-col items-center  justify-center h-full">
      <Image
        src="/logo.jpeg"
        alt="StreamChat"
        width={80}
        height={80}
        className="mb-8 rounded-full"
      />
      <div className="grid grid-cols-2 gap-4">
        {exampleMessages.map((message, index) => (
          <div
            key={index}
            className="bg-transparent border-[1px] border-[#ffffff1a] p-4 rounded-lg text-gray-400 cursor-pointer transition-all duration-500 ease-in-out hover:bg-[#2f2f2f] hover:scale-105"
            onClick={() => onMessageSelect(message)}
          >
            {message}
          </div>
        ))}
      </div>
    </div>
  );
};

export default HomeComponent;



================================================
FILE: streaming_messages_frontend/src/components/InputArea.tsx
================================================
import { useState } from "react";

export default function InputArea({
  onSendMessage,
}: {
  onSendMessage: (message: string) => void;
}) {
  const [input, setInput] = useState("");

  const handleSubmit = (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    if (input.trim()) {
      onSendMessage(input);
      setInput("");
    }
  };

  return (
    <form onSubmit={handleSubmit} className=" p-0">
      <div className="flex fixed left-1/4 w-1/2 h-[60px] mx-auto bottom-5  ">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          className=" h-full w-full rounded-[30px] px-10 focus:outline-none bg-[#2f2f2f] placeholder-white text-white"
          placeholder="Message StreamChat"
        />
        <button
          type="submit"
          className=" absolute right-[10px] bottom-[10px] w-[40px] h-[40px] rounded-[20px] bg-[#676767] text-white  hover:opacity-80 flex items-center justify-center"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="24"
            height="24"
            fill="none"
            viewBox="0 0 24 24"
          >
            <path
              fill="currentColor"
              fillRule="evenodd"
              d="M11.394 6.68a.857.857 0 0 1 1.212 0l3.857 3.857a.857.857 0 0 1-1.212 1.212l-2.394-2.394v7.36a.857.857 0 0 1-1.714 0v-7.36l-2.394 2.394a.857.857 0 1 1-1.212-1.212z"
              clipRule="evenodd"
            />
          </svg>
        </button>
      </div>
    </form>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/Interrupted.tsx
================================================
import { updateState } from "@/utils/chatApi";
import { ThreadState } from "@langchain/langgraph-sdk";
import { useState } from "react";

export interface GraphInterruptProps {
  threadId: string;
  state: ThreadState<Record<string, any>>;
  setAllowNullMessage: (value: boolean) => void;
}

export function GraphInterrupt(props: GraphInterruptProps) {
  const [newState, setNewState] = useState<Record<string, any>>({});
  const [buttonDisabled, setButtonDisabled] = useState(false);
  const [isValidJson, setIsValidJson] = useState(true);
  const [asNode, setAsNode] = useState(props.state.next[0]);
  const [stateUpdated, setStateUpdated] = useState(false);

  async function callUpdateState() {
    setButtonDisabled(true);
    await updateState(props.threadId, {
      newState,
      asNode,
    });
    setButtonDisabled(false);
    setStateUpdated(true);
    props.setAllowNullMessage(true);
  }

  if (stateUpdated) {
    return (
      <div className="flex flex-col w-2/3 mx-auto p-3 overflow-y-scroll">
        <p className="text-white mx-auto">State updated.</p>
      </div>
    );
  }

  return (
    <div className="flex flex-col w-2/3 mx-auto overflow-y-scroll pt-[-100px] pb-[100px]">
      <p className="text-lg text-white">
        Graph interrupted. Next: <code>{props.state.next}</code>
      </p>
      <div className="flex flex-col gap-2">
        <p className="text-gray-200">
          If you&apos;d like to update the state, enter valid JSON to the input
          below:
        </p>
        <input
          onChange={(e) => {
            try {
              const parsed = JSON.parse(e.target.value);
              setIsValidJson(true);
              setNewState(parsed);
            } catch (e) {
              setIsValidJson(false);
            }
          }}
          className="bg-gray-800 text-white px-4 py-2 rounded-lg mt-2"
        />
        {!isValidJson && <p className="text-red-500">Invalid JSON</p>}
        <label htmlFor="asNode" className="text-gray-200">
          As Node:
        </label>
        <input
          value={asNode}
          onChange={(e) => setAsNode(e.target.value)}
          id="asNode"
          className="bg-gray-800 text-white px-4 py-2 rounded-lg mt-2"
        />
        <button
          onClick={callUpdateState}
          disabled={buttonDisabled}
          className="bg-blue-500 text-white px-4 py-2 rounded-lg mt-2"
        >
          Update State
        </button>
      </div>
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/Message.tsx
================================================
import Markdown from "react-markdown";
import ToolCall from "./ToolCall";
import { ToolCall as ToolCallType } from "../types";
import React, { useState, useEffect } from "react";
import dynamic from "next/dynamic";

// Throws build errors if we try to import this normally
const ReactJson = dynamic(() => import("react-json-view"), { ssr: false });

export default function Message({
  text,
  rawResponse,
  sender,
  toolCalls,
}: {
  text?: string;
  rawResponse?: Record<string, any>;
  sender: string;
  toolCalls?: ToolCallType[];
}) {
  const isBot = sender === "ai";
  const [isVisible, setIsVisible] = useState(false);

  useEffect(() => {
    setIsVisible(true);
  }, []);

  let messageContent: React.ReactNode;
  if (rawResponse) {
    messageContent = (
      <ReactJson
        displayObjectSize={false}
        style={{ backgroundColor: "transparent" }}
        displayDataTypes={false}
        quotesOnKeys={false}
        enableClipboard={false}
        name={false}
        src={rawResponse}
        theme="tomorrow"
      />
    );
  } else {
    messageContent = (
      <>
        {toolCalls &&
          toolCalls.length > 0 &&
          toolCalls.map((toolCall) => (
            <ToolCall key={toolCall.id} {...toolCall} />
          ))}
        {isBot ? <Markdown>{text}</Markdown> : text}
      </>
    );
  }

  return (
    <div
      className={`flex ${
        isBot ? "justify-start" : "justify-end"
      } mb-4 relative transition-opacity duration-200 ease-in-out ${
        isVisible ? "opacity-100" : "opacity-0"
      }`}
    >
      {isBot && (
        <img
          src="/logo.jpeg"
          alt="Bot Icon"
          className="absolute left-0 top-4 w-8 h-8 rounded-full"
          style={{ transform: "translateX(-120%)" }}
        />
      )}
      <div
        className={`overflow-x-wrap break-words p-5 rounded-3xl ${
          isBot
            ? "w-full opacity-90 text-gray-200"
            : "mt-10 max-w-md text-gray-200 opacity-90"
        }`}
      >
        {messageContent}
      </div>
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/MessageList.tsx
================================================
import Message from "./Message";
import { Message as MessageType } from "../types";

export default function MessageList({ messages }: { messages: MessageType[] }) {
  return (
    <div className="pb-[100px] w-2/3 mx-auto p-10 overflow-y-scroll">
      {messages.map((message, index) => (
        <div key={index}>
          <Message
            rawResponse={message.rawResponse}
            text={message.text}
            sender={message.sender}
            toolCalls={message.toolCalls}
          />
        </div>
      ))}
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/Settings.tsx
================================================
import { useState } from "react";

export type Model = "gpt-4o" | "haiku" | "gpt-4o-mini" | "sonnet-3.5";
export type StreamMode = "messages" | "values" | "updates" | "events";

interface SettingsProps {
  onModelChange: (model: Model) => void;
  onSystemInstructionsChange: (instructions: string) => void;
  onStreamModeChange: (mode: StreamMode) => void;
  currentModel: Model;
  currentSystemInstructions: string;
  currentStreamMode: StreamMode;
}

export default function Settings({
  onModelChange,
  onSystemInstructionsChange,
  onStreamModeChange,
  currentModel,
  currentSystemInstructions,
  currentStreamMode,
}: SettingsProps) {
  const [isOpen, setIsOpen] = useState(false);
  const models: Model[] = ["gpt-4o", "haiku", "gpt-4o-mini", "sonnet-3.5"];
  const streamModes: StreamMode[] = ["messages", "values", "updates", "events"];

  return (
    <div className="absolute right-0">
      <button
        onClick={() => setIsOpen(!isOpen)}
        className="p-2 text-xl text-white"
      >
        ⚙️
      </button>
      {isOpen && (
        <div className="absolute right-0  mt-2 w-64 bg-gray-800 rounded-md shadow-lg z-10 p-4">
          <h3 className="font-bold mt-4 mb-2 text-gray-100">Model</h3>
          <select
            value={currentModel}
            onChange={(e) => {
              onModelChange(e.target.value as Model);
              setIsOpen(false);
            }}
            className="w-full p-2 border text-gray-100 rounded bg-gray-700 text-sm focus:outline-none"
          >
            {models.map((model) => (
              <option key={model} value={model}>
                {model}
              </option>
            ))}
          </select>

          <h3 className="font-bold mt-4 mb-2 text-gray-100">Stream Mode</h3>
          <select
            value={currentStreamMode}
            onChange={(e) => {
              onStreamModeChange(e.target.value as StreamMode);
              setIsOpen(false);
            }}
            className="w-full p-2 border text-gray-100 rounded bg-gray-700 text-sm focus:outline-none"
          >
            {streamModes.map((mode) => (
              <option key={mode} value={mode}>
                {mode}
              </option>
            ))}
          </select>

          <h3 className="font-bold mt-4 mb-2 text-gray-100">
            System Instructions
          </h3>
          <textarea
            value={currentSystemInstructions}
            onChange={(e) => onSystemInstructionsChange(e.target.value)}
            className="w-full h-12 p-2 border rounded bg-gray-700 text-sm focus:outline-none"
            placeholder="Enter system instructions..."
          />
        </div>
      )}
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/SkeletonMessage.tsx
================================================
export default function SkeletonMessage() {
  return (
    <div className="flex justify-start mb-4 relative">
      <img
        src="/logo.jpeg"
        alt="Bot Icon"
        className="absolute left-0 top-4 w-8 h-8 rounded-full"
        style={{ transform: "translateX(-120%)" }}
      />
      <div className="w-full p-5 rounded-3xl  ">
        <div className="h-4 bg-gray-600 rounded w-3/4 mb-2 animate-pulse"></div>
        <div className="h-4 bg-gray-600 rounded w-1/2 animate-pulse"></div>
      </div>
    </div>
  );
}



================================================
FILE: streaming_messages_frontend/src/components/ToolCall.tsx
================================================
"use client";
import React, { useState } from "react";
import dynamic from "next/dynamic";

// Throws build errors if we try to import this normally
const ReactJson = dynamic(() => import("react-json-view"), { ssr: false });

const ToolCall = ({
  name,
  args,
  result,
}: {
  name: string;
  args: any;
  result?: any;
}) => {
  const [isResultVisible, setIsResultVisible] = useState(false);

  let parsedArgs: Record<string, any> | null = null;
  let isParsedArgsDefined = false;
  try {
    if (typeof args === "string") {
      parsedArgs = JSON.parse(args);
    } else if (typeof args === "object") {
      parsedArgs = args;
    }
    isParsedArgsDefined = true;
  } catch (_) {
    // incomplete JSON, no-op
  }

  let resultString: string | null = null;
  let resultObject: Record<string, any> | null = null;
  let isResultDefined = false;
  try {
    resultString = result;
    if (resultString) {
      isResultDefined = true;
      resultObject = JSON.parse(resultString);
      // If we're able to parse result, then it's a JSON object and we should remove the string
      // so it's not able to be duplicated in the rendered UI.
      resultString = null;
    }
  } catch (_) {
    // incomplete JSON, no-op
  }

  return (
    <div className="bg-[#3a3a3a] text-white p-4 rounded-lg mb-2 text-sm relative flex flex-col gap-1">
      <div className="w-full mb-2 flex justify-between items-center">
        <div className="flex flex-row items-center justify-start gap-2">
          <span className="text-gray-400">Tool Call:</span>
          <p className="text-small opacity-80">{name}</p>
        </div>
        {isResultDefined && (
          <button
            onClick={() => setIsResultVisible(!isResultVisible)}
            className="text-gray-400 hover:text-gray-300 focus:outline-none"
          >
            {isResultVisible ? "Hide result" : "Show result"}
          </button>
        )}
      </div>

      <div className="flex flex-col gap-1">
        <p className="text-gray-400">Arguments:</p>
        <span>
          {isParsedArgsDefined && parsedArgs ? (
            <ReactJson
              displayObjectSize={false}
              style={{ backgroundColor: "transparent" }}
              displayDataTypes={false}
              quotesOnKeys={false}
              enableClipboard={false}
              name={false}
              src={parsedArgs}
              theme="tomorrow"
            />
          ) : typeof args === "string" ? (
            <p>{args}</p>
          ) : (
            <code>{JSON.stringify(args, null, 2)}</code>
          )}
        </span>
      </div>

      {isResultDefined && (
        <div
          className={`mt-2 overflow-y-scroll transition-all duration-500 ease-in-out ${
            isResultVisible ? "max-h-96" : "max-h-0"
          }`}
        >
          <span>
            <p className="text-gray-400">Result:</p>
            <div>
              {resultObject && !resultString ? (
                <ReactJson
                  displayObjectSize={false}
                  style={{
                    backgroundColor: "transparent",
                  }}
                  displayDataTypes={false}
                  quotesOnKeys={false}
                  enableClipboard={false}
                  name={false}
                  src={resultObject}
                  theme="tomorrow"
                />
              ) : null}
              {resultString && !resultObject && <p>{resultString}</p>}
            </div>
          </span>
        </div>
      )}
    </div>
  );
};

export default ToolCall;



================================================
FILE: streaming_messages_frontend/src/utils/chatApi.ts
================================================
import { StreamMode } from "@/components/Settings";
import { ThreadState, Client } from "@langchain/langgraph-sdk";

const createClient = () => {
  const apiUrl = process.env.NEXT_PUBLIC_API_URL ?? "http://localhost:3000/api";
  return new Client({
    apiUrl,
  });
};

export const createAssistant = async (graphId: string) => {
  const client = createClient();
  return client.assistants.create({ graphId });
};

export const createThread = async () => {
  const client = createClient();
  return client.threads.create();
};

export const getThreadState = async (
  threadId: string
): Promise<ThreadState<Record<string, any>>> => {
  const client = createClient();
  return client.threads.getState(threadId);
};

export const updateState = async (
  threadId: string,
  fields: {
    newState: Record<string, any>;
    asNode?: string;
  }
) => {
  const client = createClient();
  return client.threads.updateState(threadId, {
    values: fields.newState,
    asNode: fields.asNode,
  });
};

export const sendMessage = async (params: {
  threadId: string;
  assistantId: string;
  messageId: string;
  message: string | null;
  model: string;
  userId: string;
  systemInstructions: string;
  streamMode: StreamMode;
}) => {
  const client = createClient();

  let input: Record<string, any> | null = null;
  if (params.message !== null) {
    input = {
      messages: [
        {
          id: params.messageId,
          role: "human",
          content: params.message,
        },
      ],
      userId: params.userId,
    };
  }
  const config = {
    configurable: {
      model_name: params.model,
      system_instructions: params.systemInstructions,
    },
  };

  return client.runs.stream(params.threadId, params.assistantId, {
    input,
    config,
    streamMode: params.streamMode,
  });
};



================================================
FILE: streaming_messages_frontend/src/utils/cookies.ts
================================================
import Cookies from "js-cookie";

export function getCookie(key: string) {
  if (typeof window === "undefined") return null;
  return Cookies.get(key) ?? null;
}

export function setCookie(key: string, value: string) {
  if (typeof window === "undefined") return null;
  Cookies.set(key, value);
}



================================================
FILE: streaming_messages_frontend/src/utils/streamHandler.ts
================================================
import { StreamMode } from "@/components/Settings";
import { Message, ToolCall } from "../types";

export const handleStreamEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>,
  streamMode: StreamMode
) => {
  if (streamMode === "messages") {
    handleStreamMessageEvent(event, setMessages);
  } else if (streamMode === "events") {
    handleStreamEventEvent(event, setMessages);
  } else if (streamMode === "updates") {
    handleStreamUpdatesEvent(event, setMessages);
  } else if (streamMode === "values") {
    handleStreamValuesEvent(event, setMessages);
  }
};

const handleStreamMessageEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>
) => {
  if (event.event === "messages/partial") {
    event.data.forEach((dataItem: any) => {
      if (
        dataItem.type === "ai" &&
        Array.isArray(dataItem.tool_calls) &&
        dataItem.tool_calls.length > 0
      ) {
        setMessages((prevMessages) => {
          const lastMessage = prevMessages[prevMessages.length - 1];
          if (lastMessage && lastMessage.sender === "ai") {
            // Merge new tool calls with existing ones
            const mergedToolCalls = [
              ...(lastMessage.toolCalls || []),
              ...dataItem.tool_calls.filter(
                (newTc: ToolCall) =>
                  !lastMessage.toolCalls?.some(
                    (existingTc) => existingTc.id === newTc.id
                  )
              ),
            ].map((tc: ToolCall) => {
              const updatedTc = dataItem.tool_calls.find(
                (newTc: ToolCall) => newTc.id === tc.id
              );
              return updatedTc ? { ...tc, ...updatedTc } : tc;
            });

            return [
              ...prevMessages.slice(0, -1),
              {
                ...lastMessage,
                toolCalls: mergedToolCalls,
              },
            ];
          } else {
            // If the last message was not from AI, add a new message
            return [
              ...prevMessages,
              {
                text: "",
                sender: "ai",
                toolCalls: dataItem.tool_calls,
                id: dataItem.id,
              },
            ];
          }
        });
      } else if (dataItem.content) {
        setMessages((prevMessages) => {
          const lastMessage = prevMessages[prevMessages.length - 1];
          if (lastMessage && dataItem.id === lastMessage.id) {
            return [
              ...prevMessages.slice(0, -1),
              {
                ...lastMessage,
                text: dataItem.content,
              },
            ];
          } else {
            return [
              ...prevMessages,
              {
                text: dataItem.content,
                sender: "ai",
                toolCalls: [],
                id: dataItem.id,
              },
            ];
          }
        });
      }
    });
  } else if (event.event === "messages/complete") {
    const dataItem = event.data[event.data.length - 1];
    if (dataItem.type === "tool") {
      // Handle tool call completion
      const toolCall: Partial<ToolCall> = {
        id: dataItem.tool_call_id,
        name: dataItem.name,
        result: dataItem.content,
      };

      // Only set args if it's truthy
      if (dataItem.artifact) {
        toolCall.args = dataItem.artifact;
      }

      setMessages((prevMessages) => {
        const lastMessage = prevMessages[prevMessages.length - 1];
        if (lastMessage && lastMessage.sender === "ai") {
          return [
            ...prevMessages.slice(0, -1),
            {
              ...lastMessage,
              toolCalls: lastMessage.toolCalls?.map((tc) =>
                tc.id === toolCall.id ? { ...tc, ...toolCall } : tc
              ) || [toolCall as ToolCall],
            },
          ];
        } else {
          return [
            ...prevMessages,
            {
              text: "",
              sender: "ai",
              toolCalls: [toolCall as ToolCall],
              id: dataItem.id,
            },
          ];
        }
      });
    } else if (dataItem.type === "ai" && dataItem.content) {
      setMessages((prevMessages) => {
        const messageExists = prevMessages.some(
          (msg) => msg.id === dataItem.id
        );
        // Message already exists, don't add it again
        if (messageExists) {
          return prevMessages;
        }

        const messageStreamed = prevMessages.find((msg) =>
          dataItem.content.startsWith(msg.text)
        );

        if (messageStreamed) {
          // Message has already partially been streamed, update it
          return prevMessages.map((msg) => {
            if (msg.id === messageStreamed.id) {
              return { ...messageStreamed, text: dataItem.content };
            }
            return msg;
          });
        }

        return [
          ...prevMessages,
          { id: dataItem.id, text: dataItem.content, sender: "ai" },
        ];
      });
    }
  }
};

const handleStreamEventEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>
) => {
  if (event.event !== "events") return;
  const data = event.data;
  setMessages((prevMessages) => {
    return [
      ...prevMessages,
      { rawResponse: data, sender: "ai", id: data.run_id },
    ];
  });
};

const handleStreamUpdatesEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>
) => {
  if (event.event !== "updates") {
    // Not an update, return
    return;
  }
  const data = event.data;
  setMessages((prevMessages) => {
    return [
      ...prevMessages,
      { rawResponse: data, sender: "ai", id: data.run_id },
    ];
  });
};

const handleStreamValuesEvent = (
  event: any,
  setMessages: React.Dispatch<React.SetStateAction<Message[]>>
) => {
  if (event.event !== "values") {
    // Not an update, return
    return;
  }
  const data = event.data;
  setMessages((prevMessages) => {
    return [
      ...prevMessages,
      { rawResponse: data, sender: "ai", id: data.run_id },
    ];
  });
};


